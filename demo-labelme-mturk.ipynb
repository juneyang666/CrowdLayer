{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# packages for learning from crowds\n",
    "from crowd_layer.crowd_layers import CrowdsClassification, MaskedMultiCrossEntropy\n",
    "from crowd_layer.crowd_aggregators import CrowdsCategoricalAggregator\n",
    "\n",
    "# prevent tensorflow from allocating the entire GPU memory at once\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 30\n",
    "DATA_PATH = \"/Users/yangyajing/Documents/noisy_dataset/LabelMe/prepared/\"\n",
    "N_CLASSES = 8\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = np.load(f)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(10000, 4, 4, 512)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "\n",
      "Loading AMT data...\n",
      "(10000, 59)\n",
      "\n",
      "N_CLASSES: 8\n",
      "N_ANNOT: 59\n",
      "\n",
      "Loading test data...\n",
      "(1188, 4, 4, 512)\n",
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading train data...\")\n",
    "\n",
    "# images processed by VGG16\n",
    "data_train_vgg16 = load_data(DATA_PATH+\"data_train_vgg16.npy\")\n",
    "print(data_train_vgg16.shape)\n",
    "\n",
    "# ground truth labels\n",
    "labels_train = load_data(DATA_PATH+\"labels_train.npy\")\n",
    "print(labels_train.shape)\n",
    "\n",
    "# labels obtained from majority voting\n",
    "labels_train_mv = load_data(DATA_PATH+\"labels_train_mv.npy\")\n",
    "print(labels_train_mv.shape)\n",
    "\n",
    "# labels obtained by using the approach by Dawid and Skene\n",
    "labels_train_ds = load_data(DATA_PATH+\"labels_train_DS.npy\")\n",
    "print(labels_train_ds.shape)\n",
    "\n",
    "# data from Amazon Mechanical Turk\n",
    "print(\"\\nLoading AMT data...\")\n",
    "answers = load_data(DATA_PATH+\"answers.npy\")\n",
    "print(answers.shape)\n",
    "N_ANNOT = answers.shape[1]\n",
    "print(\"\\nN_CLASSES:\", N_CLASSES)\n",
    "print(\"N_ANNOT:\", N_ANNOT)\n",
    "\n",
    "# load test data\n",
    "print(\"\\nLoading test data...\")\n",
    "\n",
    "# images processed by VGG16\n",
    "data_test_vgg16 = load_data(DATA_PATH+\"data_test_vgg16.npy\")\n",
    "print(data_test_vgg16.shape)\n",
    "\n",
    "# test labels\n",
    "labels_test = load_data(DATA_PATH+\"labels_test.npy\")\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert data to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(target, n_classes):\n",
    "    targets = np.array([target]).reshape(-1)\n",
    "    one_hot_targets = np.eye(n_classes)[targets]\n",
    "    return one_hot_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to one-hot encoding...\n",
      "(10000, 8)\n",
      "(10000, 8)\n",
      "(10000, 8)\n",
      "(1188, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 8, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nConverting to one-hot encoding...\")\n",
    "labels_train_bin = one_hot(labels_train, N_CLASSES)\n",
    "print(labels_train_bin.shape)\n",
    "labels_train_mv_bin = one_hot(labels_train_mv, N_CLASSES)\n",
    "print(labels_train_mv_bin.shape)\n",
    "labels_train_ds_bin = one_hot(labels_train_ds, N_CLASSES)\n",
    "print(labels_train_ds_bin.shape)\n",
    "labels_test_bin = one_hot(labels_test, N_CLASSES)\n",
    "print(labels_test_bin.shape)\n",
    "\n",
    "answers_bin_missings = []\n",
    "for i in range(len(answers)):\n",
    "    row = []\n",
    "    for r in range(N_ANNOT):\n",
    "        if answers[i,r] == -1:\n",
    "            row.append(-1 * np.ones(N_CLASSES))\n",
    "        else:\n",
    "            row.append(one_hot(answers[i,r], N_CLASSES)[0,:])\n",
    "    answers_bin_missings.append(row)\n",
    "answers_bin_missings = np.array(answers_bin_missings).swapaxes(1,2)\n",
    "answers_bin_missings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the base deep learning model\n",
    "\n",
    "Here we shall use features representation produced by the VGG16 network as the input. Our base model is then simply composed by one densely-connected layer with 128 hidden units and an output dense layer. We use 50% dropout between the two dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_base_model():\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Flatten(input_shape=data_train_vgg16.shape[1:]))\n",
    "    base_model.add(Dense(128, activation='relu'))\n",
    "    base_model.add(Dropout(0.5))\n",
    "    base_model.add(Dense(N_CLASSES))\n",
    "    base_model.add(Activation(\"softmax\"))\n",
    "    base_model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary function for evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(model, test_data, test_labels):\n",
    "    # testset accuracy\n",
    "    preds_test = model.predict(test_data)\n",
    "    preds_test_num = np.argmax(preds_test, axis=1)\n",
    "    accuracy_test = 1.0*np.sum(preds_test_num == test_labels) / len(test_labels)\n",
    "\n",
    "    return accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the true labels (ground truth) and evaluate on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Epoch 1/50\n",
      "2s - loss: 0.5457\n",
      "Epoch 2/50\n",
      "1s - loss: 0.2074\n",
      "Epoch 3/50\n",
      "1s - loss: 0.1446\n",
      "Epoch 4/50\n",
      "1s - loss: 0.0994\n",
      "Epoch 5/50\n",
      "2s - loss: 0.0707\n",
      "Epoch 6/50\n",
      "2s - loss: 0.0543\n",
      "Epoch 7/50\n",
      "1s - loss: 0.0446\n",
      "Epoch 8/50\n",
      "2s - loss: 0.0434\n",
      "Epoch 9/50\n",
      "3s - loss: 0.0382\n",
      "Epoch 10/50\n",
      "2s - loss: 0.0383\n",
      "Epoch 11/50\n",
      "2s - loss: 0.0321\n",
      "Epoch 12/50\n",
      "2s - loss: 0.0348\n",
      "Epoch 13/50\n",
      "2s - loss: 0.0539\n",
      "Epoch 14/50\n",
      "2s - loss: 0.0381\n",
      "Epoch 15/50\n",
      "1s - loss: 0.0301\n",
      "Epoch 16/50\n",
      "1s - loss: 0.0303\n",
      "Epoch 17/50\n",
      "1s - loss: 0.0272\n",
      "Epoch 18/50\n",
      "1s - loss: 0.0321\n",
      "Epoch 19/50\n",
      "1s - loss: 0.0316\n",
      "Epoch 20/50\n",
      "1s - loss: 0.0300\n",
      "Epoch 21/50\n",
      "1s - loss: 0.0275\n",
      "Epoch 22/50\n",
      "1s - loss: 0.0193\n",
      "Epoch 23/50\n",
      "1s - loss: 0.0296\n",
      "Epoch 24/50\n",
      "1s - loss: 0.0321\n",
      "Epoch 25/50\n",
      "1s - loss: 0.0324\n",
      "Epoch 26/50\n",
      "1s - loss: 0.0245\n",
      "Epoch 27/50\n",
      "1s - loss: 0.0315\n",
      "Epoch 28/50\n",
      "1s - loss: 0.0271\n",
      "Epoch 29/50\n",
      "1s - loss: 0.0316\n",
      "Epoch 30/50\n",
      "1s - loss: 0.0231\n",
      "Epoch 31/50\n",
      "1s - loss: 0.0162\n",
      "Epoch 32/50\n",
      "1s - loss: 0.0254\n",
      "Epoch 33/50\n",
      "1s - loss: 0.0180\n",
      "Epoch 34/50\n",
      "1s - loss: 0.0233\n",
      "Epoch 35/50\n",
      "1s - loss: 0.0192\n",
      "Epoch 36/50\n",
      "1s - loss: 0.0261\n",
      "Epoch 37/50\n",
      "1s - loss: 0.0251\n",
      "Epoch 38/50\n",
      "1s - loss: 0.0214\n",
      "Epoch 39/50\n",
      "1s - loss: 0.0216\n",
      "Epoch 40/50\n",
      "1s - loss: 0.0265\n",
      "Epoch 41/50\n",
      "2s - loss: 0.0231\n",
      "Epoch 42/50\n",
      "1s - loss: 0.0246\n",
      "Epoch 43/50\n",
      "1s - loss: 0.0219\n",
      "Epoch 44/50\n",
      "1s - loss: 0.0203\n",
      "Epoch 45/50\n",
      "1s - loss: 0.0252\n",
      "Epoch 46/50\n",
      "1s - loss: 0.0263\n",
      "Epoch 47/50\n",
      "1s - loss: 0.0230\n",
      "Epoch 48/50\n",
      "1s - loss: 0.0164\n",
      "Epoch 49/50\n",
      "1s - loss: 0.0155\n",
      "Epoch 50/50\n",
      "1s - loss: 0.0164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120f5f4a8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_base_model()\n",
    "model.fit(data_train_vgg16, labels_train_bin, epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Test: 0.912\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = eval_model(model, data_test_vgg16, labels_test)\n",
    "print \"Accuracy: Test: %.3f\" % (accuracy_test,) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the output of majority voting and evaluate on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2s - loss: 0.9171\n",
      "Epoch 2/50\n",
      "2s - loss: 0.5398\n",
      "Epoch 3/50\n",
      "2s - loss: 0.3974\n",
      "Epoch 4/50\n",
      "2s - loss: 0.3053\n",
      "Epoch 5/50\n",
      "2s - loss: 0.2459\n",
      "Epoch 6/50\n",
      "2s - loss: 0.1892\n",
      "Epoch 7/50\n",
      "2s - loss: 0.1580\n",
      "Epoch 8/50\n",
      "2s - loss: 0.1421\n",
      "Epoch 9/50\n",
      "2s - loss: 0.1291\n",
      "Epoch 10/50\n",
      "2s - loss: 0.1125\n",
      "Epoch 11/50\n",
      "2s - loss: 0.1062\n",
      "Epoch 12/50\n",
      "2s - loss: 0.0980\n",
      "Epoch 13/50\n",
      "1s - loss: 0.0879\n",
      "Epoch 14/50\n",
      "1s - loss: 0.0839\n",
      "Epoch 15/50\n",
      "1s - loss: 0.0748\n",
      "Epoch 16/50\n",
      "1s - loss: 0.0900\n",
      "Epoch 17/50\n",
      "1s - loss: 0.0791\n",
      "Epoch 18/50\n",
      "1s - loss: 0.0760\n",
      "Epoch 19/50\n",
      "1s - loss: 0.0677\n",
      "Epoch 20/50\n",
      "1s - loss: 0.0665\n",
      "Epoch 21/50\n",
      "2s - loss: 0.0638\n",
      "Epoch 22/50\n",
      "2s - loss: 0.0615\n",
      "Epoch 23/50\n",
      "2s - loss: 0.0833\n",
      "Epoch 24/50\n",
      "2s - loss: 0.0940\n",
      "Epoch 25/50\n",
      "1s - loss: 0.0862\n",
      "Epoch 26/50\n",
      "1s - loss: 0.0705\n",
      "Epoch 27/50\n",
      "1s - loss: 0.0700\n",
      "Epoch 28/50\n",
      "2s - loss: 0.0968\n",
      "Epoch 29/50\n",
      "2s - loss: 0.0768\n",
      "Epoch 30/50\n",
      "2s - loss: 0.0679\n",
      "Epoch 31/50\n",
      "2s - loss: 0.0699\n",
      "Epoch 32/50\n",
      "2s - loss: 0.0669\n",
      "Epoch 33/50\n",
      "2s - loss: 0.0742\n",
      "Epoch 34/50\n",
      "2s - loss: 0.0697\n",
      "Epoch 35/50\n",
      "2s - loss: 0.0623\n",
      "Epoch 36/50\n",
      "2s - loss: 0.0526\n",
      "Epoch 37/50\n",
      "2s - loss: 0.0529\n",
      "Epoch 38/50\n",
      "2s - loss: 0.0528\n",
      "Epoch 39/50\n",
      "2s - loss: 0.0579\n",
      "Epoch 40/50\n",
      "2s - loss: 0.0629\n",
      "Epoch 41/50\n",
      "2s - loss: 0.0587\n",
      "Epoch 42/50\n",
      "2s - loss: 0.0576\n",
      "Epoch 43/50\n",
      "2s - loss: 0.0458\n",
      "Epoch 44/50\n",
      "2s - loss: 0.0496\n",
      "Epoch 45/50\n",
      "2s - loss: 0.0596\n",
      "Epoch 46/50\n",
      "2s - loss: 0.0509\n",
      "Epoch 47/50\n",
      "1s - loss: 0.0475\n",
      "Epoch 48/50\n",
      "2s - loss: 0.0399\n",
      "Epoch 49/50\n",
      "2s - loss: 0.0512\n",
      "Epoch 50/50\n",
      "1s - loss: 0.0375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13797d438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_base_model()\n",
    "model.fit(data_train_vgg16, labels_train_mv_bin, epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Test: 0.785\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = eval_model(model, data_test_vgg16, labels_test)\n",
    "print(\"Accuracy: Test: %.3f\" % (accuracy_test,)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on the output of Dawid & Skene [1] and evaluate on testset\n",
    "\n",
    "[1] Dawid, A.P. and Skene, A.M., 1979. Maximum likelihood estimation of observer error-rates using the EM algorithm. Applied statistics, pp.20-28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2s - loss: 0.8759\n",
      "Epoch 2/50\n",
      "1s - loss: 0.5004\n",
      "Epoch 3/50\n",
      "1s - loss: 0.3460\n",
      "Epoch 4/50\n",
      "1s - loss: 0.2597\n",
      "Epoch 5/50\n",
      "1s - loss: 0.2071\n",
      "Epoch 6/50\n",
      "1s - loss: 0.1654\n",
      "Epoch 7/50\n",
      "1s - loss: 0.1487\n",
      "Epoch 8/50\n",
      "1s - loss: 0.1245\n",
      "Epoch 9/50\n",
      "1s - loss: 0.1215\n",
      "Epoch 10/50\n",
      "1s - loss: 0.1050\n",
      "Epoch 11/50\n",
      "1s - loss: 0.0912\n",
      "Epoch 12/50\n",
      "2s - loss: 0.0870\n",
      "Epoch 13/50\n",
      "2s - loss: 0.0780\n",
      "Epoch 14/50\n",
      "2s - loss: 0.0760\n",
      "Epoch 15/50\n",
      "1s - loss: 0.0814\n",
      "Epoch 16/50\n",
      "1s - loss: 0.0671\n",
      "Epoch 17/50\n",
      "1s - loss: 0.0709\n",
      "Epoch 18/50\n",
      "1s - loss: 0.0806\n",
      "Epoch 19/50\n",
      "1s - loss: 0.0660\n",
      "Epoch 20/50\n",
      "1s - loss: 0.0583\n",
      "Epoch 21/50\n",
      "1s - loss: 0.0532\n",
      "Epoch 22/50\n",
      "1s - loss: 0.0532\n",
      "Epoch 23/50\n",
      "1s - loss: 0.0666\n",
      "Epoch 24/50\n",
      "2s - loss: 0.0595\n",
      "Epoch 25/50\n",
      "2s - loss: 0.0631\n",
      "Epoch 26/50\n",
      "1s - loss: 0.0480\n",
      "Epoch 27/50\n",
      "1s - loss: 0.0588\n",
      "Epoch 28/50\n",
      "1s - loss: 0.0703\n",
      "Epoch 29/50\n",
      "1s - loss: 0.0613\n",
      "Epoch 30/50\n",
      "1s - loss: 0.0577\n",
      "Epoch 31/50\n",
      "1s - loss: 0.0606\n",
      "Epoch 32/50\n",
      "1s - loss: 0.0523\n",
      "Epoch 33/50\n",
      "1s - loss: 0.0389\n",
      "Epoch 34/50\n",
      "1s - loss: 0.0399\n",
      "Epoch 35/50\n",
      "1s - loss: 0.0356\n",
      "Epoch 36/50\n",
      "1s - loss: 0.0528\n",
      "Epoch 37/50\n",
      "1s - loss: 0.0416\n",
      "Epoch 38/50\n",
      "1s - loss: 0.0488\n",
      "Epoch 39/50\n",
      "1s - loss: 0.0437\n",
      "Epoch 40/50\n",
      "2s - loss: 0.0464\n",
      "Epoch 41/50\n",
      "2s - loss: 0.0443\n",
      "Epoch 42/50\n",
      "1s - loss: 0.0491\n",
      "Epoch 43/50\n",
      "1s - loss: 0.0589\n",
      "Epoch 44/50\n",
      "1s - loss: 0.0444\n",
      "Epoch 45/50\n",
      "1s - loss: 0.0574\n",
      "Epoch 46/50\n",
      "1s - loss: 0.0631\n",
      "Epoch 47/50\n",
      "1s - loss: 0.0529\n",
      "Epoch 48/50\n",
      "1s - loss: 0.0575\n",
      "Epoch 49/50\n",
      "1s - loss: 0.0510\n",
      "Epoch 50/50\n",
      "2s - loss: 0.0490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x139defcc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_base_model()\n",
    "model.fit(data_train_vgg16, labels_train_ds_bin, epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Test: 0.813\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = eval_model(model, data_test_vgg16, labels_test)\n",
    "print(\"Accuracy: Test: %.3f\" % (accuracy_test,)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using EM approach and evaluate on testset\n",
    "\n",
    "The CrowdsCategoricalAggregator class acts as a wrapper for the base model that computed the EM steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.769\n",
      "M-step\n",
      "loss: 0.908360270690918\n",
      "Epoch: 2\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8223\n",
      "M-step\n",
      "loss: 0.09061147568225861\n",
      "Epoch: 3\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8335\n",
      "M-step\n",
      "loss: 0.08477370660305023\n",
      "Epoch: 4\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8456\n",
      "M-step\n",
      "loss: 0.07502520937919617\n",
      "Epoch: 5\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8512\n",
      "M-step\n",
      "loss: 0.06299123305082321\n",
      "Epoch: 6\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8568\n",
      "M-step\n",
      "loss: 0.0570142375767231\n",
      "Epoch: 7\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8595\n",
      "M-step\n",
      "loss: 0.05246899654865265\n",
      "Epoch: 8\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8554\n",
      "M-step\n",
      "loss: 0.05003881833553314\n",
      "Epoch: 9\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.863\n",
      "M-step\n",
      "loss: 0.04662610713839531\n",
      "Epoch: 10\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8667\n",
      "M-step\n",
      "loss: 0.03936486002206802\n",
      "Epoch: 11\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8612\n",
      "M-step\n",
      "loss: 0.04093037679195404\n",
      "Epoch: 12\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8555\n",
      "M-step\n",
      "loss: 0.04317114043459296\n",
      "Epoch: 13\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8595\n",
      "M-step\n",
      "loss: 0.03836240803822875\n",
      "Epoch: 14\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8599\n",
      "M-step\n",
      "loss: 0.03218354996740818\n",
      "Epoch: 15\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8621\n",
      "M-step\n",
      "loss: 0.03369150398373604\n",
      "Epoch: 16\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8639\n",
      "M-step\n",
      "loss: 0.03271470321565866\n",
      "Epoch: 17\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8625\n",
      "M-step\n",
      "loss: 0.03461288684606552\n",
      "Epoch: 18\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8624\n",
      "M-step\n",
      "loss: 0.03888297407925129\n",
      "Epoch: 19\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8566\n",
      "M-step\n",
      "loss: 0.035376147957146165\n",
      "Epoch: 20\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8604\n",
      "M-step\n",
      "loss: 0.031848373115062716\n",
      "Epoch: 21\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8621\n",
      "M-step\n",
      "loss: 0.029093792095780373\n",
      "Epoch: 22\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8597\n",
      "M-step\n",
      "loss: 0.033058907493948936\n",
      "Epoch: 23\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8613\n",
      "M-step\n",
      "loss: 0.0546704165160656\n",
      "Epoch: 24\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8626\n",
      "M-step\n",
      "loss: 0.046963941963389516\n",
      "Epoch: 25\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8615\n",
      "M-step\n",
      "loss: 0.031907305802870545\n",
      "Epoch: 26\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8591\n",
      "M-step\n",
      "loss: 0.028092463923990726\n",
      "Epoch: 27\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8621\n",
      "M-step\n",
      "loss: 0.029200277806818484\n",
      "Epoch: 28\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8628\n",
      "M-step\n",
      "loss: 0.02933555623590946\n",
      "Epoch: 29\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8627\n",
      "M-step\n",
      "loss: 0.03319451317489147\n",
      "Epoch: 30\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8655\n",
      "M-step\n",
      "loss: 0.02863195124566555\n",
      "Epoch: 31\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8663\n",
      "M-step\n",
      "loss: 0.03612029504925013\n",
      "Epoch: 32\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8584\n",
      "M-step\n",
      "loss: 0.026919672457128764\n",
      "Epoch: 33\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8643\n",
      "M-step\n",
      "loss: 0.031201953262090684\n",
      "Epoch: 34\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8633\n",
      "M-step\n",
      "loss: 0.03537533142194152\n",
      "Epoch: 35\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8648\n",
      "M-step\n",
      "loss: 0.023196144688129423\n",
      "Epoch: 36\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8625\n",
      "M-step\n",
      "loss: 0.023446639330126345\n",
      "Epoch: 37\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8612\n",
      "M-step\n",
      "loss: 0.0260265152618289\n",
      "Epoch: 38\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8629\n",
      "M-step\n",
      "loss: 0.023477948757261037\n",
      "Epoch: 39\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8632\n",
      "M-step\n",
      "loss: 0.025487475843261928\n",
      "Epoch: 40\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8631\n",
      "M-step\n",
      "loss: 0.03064219309836626\n",
      "Epoch: 41\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8634\n",
      "M-step\n",
      "loss: 0.01904688823968172\n",
      "Epoch: 42\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.863\n",
      "M-step\n",
      "loss: 0.028470038873702287\n",
      "Epoch: 43\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8632\n",
      "M-step\n",
      "loss: 0.01971976586841047\n",
      "Epoch: 44\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8652\n",
      "M-step\n",
      "loss: 0.02604143834337592\n",
      "Epoch: 45\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8644\n",
      "M-step\n",
      "loss: 0.02776998918503523\n",
      "Epoch: 46\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8635\n",
      "M-step\n",
      "loss: 0.028528327019512655\n",
      "Epoch: 47\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8627\n",
      "M-step\n",
      "loss: 0.024002485171705484\n",
      "Epoch: 48\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8638\n",
      "M-step\n",
      "loss: 0.022393567860871554\n",
      "Epoch: 49\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8642\n",
      "M-step\n",
      "loss: 0.021846921788901092\n",
      "Epoch: 50\n",
      "E-step\n",
      "Adjusted ground truth accuracy: 0.8635\n",
      "M-step\n",
      "loss: 0.01845197768062353\n"
     ]
    }
   ],
   "source": [
    "model = build_base_model()\n",
    "crowds_agg = CrowdsCategoricalAggregator(model, data_train_vgg16, answers, batch_size=BATCH_SIZE)\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(\"Epoch:\", epoch+1)\n",
    "    \n",
    "    # E-step\n",
    "    ground_truth_est = crowds_agg.e_step()\n",
    "    print(\"Adjusted ground truth accuracy:\", 1.0*np.sum(np.argmax(ground_truth_est, axis=1) == labels_train) / len(labels_train))\n",
    "    \n",
    "    # M-step\n",
    "    model, pi = crowds_agg.m_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Test: 0.816\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = eval_model(model, data_test_vgg16, labels_test)\n",
    "print(\"Accuracy: Test: %.3f\" % (accuracy_test,)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using proposed DL-MW approach and evaluate on testset\n",
    "\n",
    "We start by adding a new layer (CrowdsClassification) on top of our neural network. We then require a special loss (MaskedMultiCrossEntropy) to handle the missing labels from some of the annotators (encoded as \"-1\").\n",
    "\n",
    "Notice how the training is faster then the EM approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1205: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2755: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/yangyajing/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1290: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/yangyajing/Documents/GitHub/CrowdLayer/crowd_layer/crowd_layers.py:266: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Epoch 1/50\n",
      "6s - loss: 0.0722\n",
      "Epoch 2/50\n",
      "2s - loss: 0.0647\n",
      "Epoch 3/50\n",
      "2s - loss: 0.0614\n",
      "Epoch 4/50\n",
      "3s - loss: 0.0587\n",
      "Epoch 5/50\n",
      "2s - loss: 0.0564\n",
      "Epoch 6/50\n",
      "3s - loss: 0.0543\n",
      "Epoch 7/50\n",
      "2s - loss: 0.0522\n",
      "Epoch 8/50\n",
      "2s - loss: 0.0505\n",
      "Epoch 9/50\n",
      "2s - loss: 0.0489\n",
      "Epoch 10/50\n",
      "3s - loss: 0.0474\n",
      "Epoch 11/50\n",
      "3s - loss: 0.0458\n",
      "Epoch 12/50\n",
      "2s - loss: 0.0446\n",
      "Epoch 13/50\n",
      "3s - loss: 0.0435\n",
      "Epoch 14/50\n",
      "2s - loss: 0.0425\n",
      "Epoch 15/50\n",
      "3s - loss: 0.0414\n",
      "Epoch 16/50\n",
      "3s - loss: 0.0404\n",
      "Epoch 17/50\n",
      "3s - loss: 0.0394\n",
      "Epoch 18/50\n",
      "2s - loss: 0.0385\n",
      "Epoch 19/50\n",
      "2s - loss: 0.0374\n",
      "Epoch 20/50\n",
      "2s - loss: 0.0365\n",
      "Epoch 21/50\n",
      "2s - loss: 0.0361\n",
      "Epoch 22/50\n",
      "2s - loss: 0.0355\n",
      "Epoch 23/50\n",
      "2s - loss: 0.0349\n",
      "Epoch 24/50\n",
      "3s - loss: 0.0341\n",
      "Epoch 25/50\n",
      "3s - loss: 0.0334\n",
      "Epoch 26/50\n",
      "3s - loss: 0.0329\n",
      "Epoch 27/50\n",
      "3s - loss: 0.0325\n",
      "Epoch 28/50\n",
      "3s - loss: 0.0318\n",
      "Epoch 29/50\n",
      "2s - loss: 0.0313\n",
      "Epoch 30/50\n",
      "3s - loss: 0.0309\n",
      "Epoch 31/50\n",
      "3s - loss: 0.0303\n",
      "Epoch 32/50\n",
      "4s - loss: 0.0299\n",
      "Epoch 33/50\n",
      "3s - loss: 0.0293\n",
      "Epoch 34/50\n",
      "3s - loss: 0.0290\n",
      "Epoch 35/50\n",
      "3s - loss: 0.0290\n",
      "Epoch 36/50\n",
      "3s - loss: 0.0284\n",
      "Epoch 37/50\n",
      "3s - loss: 0.0284\n",
      "Epoch 38/50\n",
      "3s - loss: 0.0276\n",
      "Epoch 39/50\n",
      "3s - loss: 0.0271\n",
      "Epoch 40/50\n",
      "3s - loss: 0.0271\n",
      "Epoch 41/50\n",
      "3s - loss: 0.0268\n",
      "Epoch 42/50\n",
      "2s - loss: 0.0265\n",
      "Epoch 43/50\n",
      "2s - loss: 0.0262\n",
      "Epoch 44/50\n",
      "2s - loss: 0.0259\n",
      "Epoch 45/50\n",
      "2s - loss: 0.0253\n",
      "Epoch 46/50\n",
      "2s - loss: 0.0253\n",
      "Epoch 47/50\n",
      "2s - loss: 0.0249\n",
      "Epoch 48/50\n",
      "2s - loss: 0.0245\n",
      "Epoch 49/50\n",
      "3s - loss: 0.0244\n",
      "Epoch 50/50\n",
      "2s - loss: 0.0240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13602dbe0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_base_model()\n",
    "\n",
    "# add crowds layer on top of the base model\n",
    "model.add(CrowdsClassification(N_CLASSES, N_ANNOT, conn_type=\"VW\"))\n",
    "\n",
    "# instantiate specialized masked loss to handle missing answers\n",
    "loss = MaskedMultiCrossEntropy().loss\n",
    "\n",
    "# compile model with masked loss and train\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "model.fit(data_train_vgg16, answers_bin_missings, epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before evaluating our model, we need to remove the crowds layer used during training in order to expose the aggregation (bottleneck) layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Test: 0.829\n"
     ]
    }
   ],
   "source": [
    "# save weights from crowds layer for later\n",
    "weights = model.layers[5].get_weights()\n",
    "\n",
    "# remove crowds layer before making predictions\n",
    "model.pop() \n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "accuracy_test = eval_model(model, data_test_vgg16, labels_test)\n",
    "print(\"Accuracy: Test: %.3f\" % (accuracy_test,)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model using MW with softmax noise adaption layer approach and evaluate on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(950, 4, 4, 512)\n",
      "(950, 8)\n",
      "baseline_confusion of annotator 0/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 146.   0.   0.  18.   7.   0.   0.]\n",
      " [  0.   0.  70.   0.   6.   0.   0.   0.]\n",
      " [  0.   0.   0. 119.   0.   0.   1.   2.]\n",
      " [  0.   0.   0.   0. 219.   0.   0.   0.]\n",
      " [  0.   4.   0.   0.   7.  93.   0.   0.]\n",
      " [  0.   0.   0.  11.   0.   0. 109.   0.]\n",
      " [  0.   0.   0.  40.   0.   0.   0.  98.]]\n",
      "(100, 4, 4, 512)\n",
      "(100, 8)\n",
      "baseline_confusion of annotator 1/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 10.  0.  0.  0. 10.  0.  0.]\n",
      " [ 0.  0. 20.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0.  0.  0. 11. 10.  0.  0.]\n",
      " [ 0.  0.  0.  0.  9.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 20.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.]]\n",
      "(590, 4, 4, 512)\n",
      "(590, 8)\n",
      "baseline_confusion of annotator 2/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  40.   0.   0.  35.  11.   0.   0.]\n",
      " [  0.   0.  40.   0.   0.   0.  20.   0.]\n",
      " [  0.   0.   0.  68.   0.   0.   0.   7.]\n",
      " [  0.   0.   0.   0. 125.   0.   0.   0.]\n",
      " [  0.   0.   0.  10.   0.  69.   0.   0.]\n",
      " [  0.   0.   0.   3.   0.   0.  60.   0.]\n",
      " [  0.   0.   0.   9.   0.   0.   0.  93.]]\n",
      "(460, 4, 4, 512)\n",
      "(460, 8)\n",
      "baseline_confusion of annotator 3/59\n",
      "[[  0.   0.   0.   0.   0.  10.   0.   0.]\n",
      " [  0.  20.   0.   0.   0.  18.  10.   0.]\n",
      " [  0.   0.  60.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  25.   7.]\n",
      " [  0.   0.   0.   0. 100.   0.   0.   0.]\n",
      " [  0.  10.   0.   0.  10.  12.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  75.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0. 103.]]\n",
      "(810, 4, 4, 512)\n",
      "(810, 8)\n",
      "baseline_confusion of annotator 4/59\n",
      "[[  0.  10.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 189.   0.   0.   7.   0.   0.   0.]\n",
      " [  0.   0.  40.   0.   0.   0.  10.   0.]\n",
      " [  0.   0.   0.  72.   0.   0.   0.   5.]\n",
      " [  0.   1.   0.   0. 163.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  40.   0.   0.]\n",
      " [  0.   0.   0.  38.   0.   0.  90.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0. 145.]]\n",
      "(520, 4, 4, 512)\n",
      "(520, 8)\n",
      "baseline_confusion of annotator 5/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 90.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 40.  0.  0.  0.  9.  0.]\n",
      " [ 0.  0.  0. 15.  0.  0.  4. 26.]\n",
      " [ 0.  0.  0.  0. 90.  3.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 67.  0.  0.]\n",
      " [ 0.  0.  0. 35.  0.  0. 37. 10.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0. 84.]]\n",
      "(750, 4, 4, 512)\n",
      "(750, 8)\n",
      "baseline_confusion of annotator 6/59\n",
      "[[  0.   0.   0.   0.   0.   2.   0.   0.]\n",
      " [  0. 108.   0.   0.   0.  14.   0.   0.]\n",
      " [  0.   0.  90.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0. 103.   0.   0.   0.  20.]\n",
      " [  0.   1.   0.   0. 134.   2.   0.   0.]\n",
      " [  0.   1.   0.  10.   6.  92.   0.   0.]\n",
      " [  0.   0.   0.  29.   0.   0.  70.  10.]\n",
      " [  0.   0.   0.   8.   0.   0.   0.  50.]]\n",
      "(250, 4, 4, 512)\n",
      "(250, 8)\n",
      "baseline_confusion of annotator 7/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 13.  0.  0. 10.  0. 10.  0.]\n",
      " [ 0.  0. 10.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 10. 25.]\n",
      " [ 0.  0.  0.  0. 40.  0.  0.  0.]\n",
      " [ 0.  7.  0.  0.  0. 20.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 30.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 75.]]\n",
      "(210, 4, 4, 512)\n",
      "(210, 8)\n",
      "baseline_confusion of annotator 8/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 30.  0.  0.  0.  7.  0.  0.]\n",
      " [ 0.  0. 20.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 23.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 40.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 23.  0.  0.]\n",
      " [ 0.  0.  0.  7.  0.  0. 30.  0.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0. 20.]]\n",
      "(580, 4, 4, 512)\n",
      "(580, 8)\n",
      "baseline_confusion of annotator 9/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 130.   0.   0.   0.   3.   0.   0.]\n",
      " [  0.   0.  20.   6.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.  81.   0.   0.   0.  20.]\n",
      " [  0.   0.   0.   0. 150.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.  47.  10.   0.]\n",
      " [  0.   0.   0.   4.   0.   0.  30.   0.]\n",
      " [  0.   0.   0.  19.   0.   0.   0.  60.]]\n",
      "(1100, 4, 4, 512)\n",
      "(1100, 8)\n",
      "baseline_confusion of annotator 10/59\n",
      "[[  0.   2.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 232.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0. 109.   0.   0.   0.  15.   0.]\n",
      " [  0.   0.   0. 109.   0.   0.   7.  21.]\n",
      " [  0.   8.   0.   0. 140.  37.   8.   0.]\n",
      " [  0.   8.   0.   0.   0.  73.   5.   0.]\n",
      " [  0.   0.   1.   8.   0.   0. 105.   0.]\n",
      " [  0.   0.   0.  43.   0.   0.   0. 169.]]\n",
      "(950, 4, 4, 512)\n",
      "(950, 8)\n",
      "baseline_confusion of annotator 11/59\n",
      "[[  0.   0.   0.   0.   0.  10.   0.   0.]\n",
      " [  0. 114.   0.   0.   1.   0.   0.   0.]\n",
      " [  0.   0. 102.   0.   0.  10.   0.   0.]\n",
      " [  0.   0.   4.  89.   0.  11.  21.   1.]\n",
      " [  0.   3.   0.   0. 169.   0.   0.   0.]\n",
      " [  0.  43.   0.   0.  30.  10.   0.   0.]\n",
      " [  0.   0.   4.  26.   0.   9. 129.   0.]\n",
      " [  0.   0.   0.  15.   0.   0.   0. 149.]]\n",
      "(150, 4, 4, 512)\n",
      "(150, 8)\n",
      "baseline_confusion of annotator 12/59\n",
      "[[ 0.  0.  0.  0. 10.  0.  0.  0.]\n",
      " [ 0. 20.  0.  0.  0.  0. 10.  0.]\n",
      " [ 0.  0. 10.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 50.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 10.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. 20.  0.]\n",
      " [ 0.  0.  0. 10.  0.  0.  0.  0.]]\n",
      "(220, 4, 4, 512)\n",
      "(220, 8)\n",
      "baseline_confusion of annotator 13/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 40.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 20. 20.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 30.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 40.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 10.  0.  0.]\n",
      " [ 0.  0.  0. 40.  0.  0.  0. 10.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 10.]]\n",
      "(260, 4, 4, 512)\n",
      "(260, 8)\n",
      "baseline_confusion of annotator 14/59\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. 60.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. 40.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0. 47.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0. 40.  8.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. 12.  0.  0.]\n",
      " [ 0.  0.  0. 33.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0. 20.]]\n",
      "(580, 4, 4, 512)\n",
      "(580, 8)\n",
      "baseline_confusion of annotator 15/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  60.   0.   0.   8.   3.   0.   0.]\n",
      " [  0.   0.  30.   0.   0.   0.  10.   0.]\n",
      " [  0.   0.   0. 104.   0.   0.   0.  10.]\n",
      " [  0.   0.   0.   0. 118.   0.   0.   0.]\n",
      " [  0.   0.   0.  10.   4.  37.   0.   0.]\n",
      " [  0.   0.  10.  63.   0.   0.  20.   0.]\n",
      " [  0.   0.   0.   3.   0.   0.   0.  90.]]\n",
      "(880, 4, 4, 512)\n",
      "(880, 8)\n",
      "baseline_confusion of annotator 16/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0. 158.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.  50.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.  20.   0.   0.  10.  13.]\n",
      " [  0.   2.   0.   0. 190.   0.   0.   0.]\n",
      " [  0.   0.  10.   0.   0. 130.   0.   0.]\n",
      " [  0.   0.   0.   0.   0.   0. 150.   0.]\n",
      " [  0.   0.   0.  10.   0.   0.   0. 137.]]\n",
      "(780, 4, 4, 512)\n",
      "(780, 8)\n",
      "baseline_confusion of annotator 17/59\n",
      "[[  0.   0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  60.   0.   0.   1.   0.   0.   0.]\n",
      " [  0.  10.  47.   0.   0.   0.  25.   0.]\n",
      " [  0.   0.   9.  30.  10.   0.  67.  26.]\n",
      " [  0.   0.   4.   0. 135.   0.   0.   0.]\n",
      " [  0.   0.   0.   0.  34.  80.   5.   0.]\n",
      " [  0.   0.   0.  10.   0.   0. 103.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0. 124.]]\n",
      "(780, 4, 4, 512)\n",
      "(780, 8)\n",
      "baseline_confusion of annotator 18/59\n",
      "[[  0.   0.   0.   0.   0.  10.   0.   0.]\n",
      " [  0.  72.   0.   0.  10.   0.  10.   0.]\n",
      " [  0.   0.  50.   0.   0.   0.   0.   0.]\n",
      " [  0.   0.   0.  54.   0.   0.  12.  10.]\n",
      " [  0.   8.   0.   0. 191.   3.   0.   0.]\n",
      " [  0.   0.   0.   0.   9.  57.   0.   0.]\n",
      " [  0.   0.   0.   6.   0.   0. 148.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.  10. 120.]]\n",
      "(1140, 4, 4, 512)\n",
      "(1140, 8)\n"
     ]
    }
   ],
   "source": [
    "baseline_confusion = []\n",
    "for a in range(N_ANNOT):\n",
    "    # get data, label, answer(noisy label) that the annotator labeled.\n",
    "    data_train_vgg16_a = data_train_vgg16[answers[:,a]>0]\n",
    "    print(data_train_vgg16_a.shape)\n",
    "    answers_a = answers[answers[:,a]>0,a]\n",
    "    answers_a_mv_bin = one_hot(answers_a, N_CLASSES)\n",
    "    print(answers_a_mv_bin.shape)\n",
    "    model_a = build_base_model()\n",
    "    model_a.fit(data_train_vgg16_a, answers_a_mv_bin, epochs=N_EPOCHS, shuffle=True, batch_size=20, verbose=0)\n",
    "    baseline_predict_a = model.predict(data_train_vgg16_a,batch_size=BATCH_SIZE)\n",
    "    baseline_predict_a = np.argmax(baseline_predict_a, axis=-1)\n",
    "    baseline_confusion_a = np.zeros((N_CLASSES, N_CLASSES))\n",
    "    for n, p in zip(answers_a, baseline_predict_a):\n",
    "        baseline_confusion_a[p, n] += 1.\n",
    "    print('baseline_confusion of annotator %d/%d'%(a, N_ANNOT))\n",
    "    print(baseline_confusion_a)\n",
    "    baseline_confusion.append(baseline_confusion_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,  30.,   0.,   0.,   0., 100.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build_base_model()\n",
    "\n",
    "# add crowds layer on top of the base model\n",
    "model.add(CrowdsClassification(N_CLASSES, N_ANNOT, conn_type=\"VW\"))\n",
    "\n",
    "# instantiate specialized masked loss to handle missing answers\n",
    "loss = MaskedMultiCrossEntropy().loss\n",
    "\n",
    "# compile model with masked loss and train\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "model.fit(data_train_vgg16, answers_bin_missings, epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[9.99999999e-01, 9.99999997e-01, 9.99999999e-01, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [8.33333333e-11, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [8.33333333e-11, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        ...,\n",
       "        [8.33333333e-11, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [8.33333333e-11, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [8.33333333e-11, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01]],\n",
       "\n",
       "       [[7.69230769e-11, 9.99999992e-10, 9.99999999e-11, ...,\n",
       "         4.99999998e-10, 1.25000000e-01, 9.99999992e-10],\n",
       "        [9.23076923e-01, 9.99999993e-01, 4.00000000e-01, ...,\n",
       "         9.99999997e-01, 1.25000000e-01, 9.99999993e-01],\n",
       "        [7.69230769e-11, 9.99999992e-10, 1.00000000e-01, ...,\n",
       "         4.99999998e-10, 1.25000000e-01, 9.99999992e-10],\n",
       "        ...,\n",
       "        [7.69230769e-11, 9.99999992e-10, 1.00000000e-01, ...,\n",
       "         4.99999998e-10, 1.25000000e-01, 9.99999992e-10],\n",
       "        [7.69230769e-11, 9.99999992e-10, 9.99999999e-11, ...,\n",
       "         4.99999998e-10, 1.25000000e-01, 9.99999992e-10],\n",
       "        [7.69230769e-11, 9.99999992e-10, 9.99999999e-11, ...,\n",
       "         4.99999998e-10, 1.25000000e-01, 9.99999992e-10]],\n",
       "\n",
       "       [[1.11111111e-10, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [1.11111111e-10, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [7.77777777e-01, 9.99999997e-01, 3.75000000e-01, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        ...,\n",
       "        [1.11111111e-10, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [1.11111111e-01, 4.99999998e-10, 5.00000000e-01, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01],\n",
       "        [1.11111111e-10, 4.99999998e-10, 1.25000000e-10, ...,\n",
       "         1.25000000e-01, 1.25000000e-01, 1.25000000e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[5.55555556e-02, 4.99999998e-10, 2.14285714e-01, ...,\n",
       "         1.25000000e-01, 4.99999998e-10, 1.25000000e-01],\n",
       "        [1.66666667e-01, 4.99999998e-10, 7.14285714e-11, ...,\n",
       "         1.25000000e-01, 4.99999998e-10, 1.25000000e-01],\n",
       "        [5.55555555e-11, 4.99999998e-10, 7.14285714e-11, ...,\n",
       "         1.25000000e-01, 4.99999998e-10, 1.25000000e-01],\n",
       "        ...,\n",
       "        [5.55555555e-01, 4.99999999e-01, 5.00000000e-01, ...,\n",
       "         1.25000000e-01, 9.99999997e-01, 1.25000000e-01],\n",
       "        [5.55555555e-11, 4.99999998e-10, 7.14285714e-11, ...,\n",
       "         1.25000000e-01, 4.99999998e-10, 1.25000000e-01],\n",
       "        [5.55555555e-11, 4.99999998e-10, 7.14285714e-11, ...,\n",
       "         1.25000000e-01, 4.99999998e-10, 1.25000000e-01]],\n",
       "\n",
       "       [[1.11111111e-10, 9.99999992e-10, 2.00000000e-10, ...,\n",
       "         4.99999998e-10, 9.99999992e-10, 1.25000000e-01],\n",
       "        [1.11111111e-10, 9.99999992e-10, 2.00000000e-10, ...,\n",
       "         4.99999998e-10, 9.99999992e-10, 1.25000000e-01],\n",
       "        [1.11111111e-10, 9.99999992e-10, 2.00000000e-10, ...,\n",
       "         4.99999998e-10, 9.99999992e-10, 1.25000000e-01],\n",
       "        ...,\n",
       "        [1.11111111e-10, 9.99999992e-10, 2.00000000e-10, ...,\n",
       "         4.99999998e-10, 9.99999992e-10, 1.25000000e-01],\n",
       "        [7.77777777e-01, 9.99999993e-01, 7.99999999e-01, ...,\n",
       "         9.99999997e-01, 9.99999993e-01, 1.25000000e-01],\n",
       "        [1.11111111e-10, 9.99999992e-10, 2.00000000e-10, ...,\n",
       "         4.99999998e-10, 9.99999992e-10, 1.25000000e-01]],\n",
       "\n",
       "       [[7.69230769e-11, 1.25000000e-01, 1.25000000e-10, ...,\n",
       "         9.99999992e-10, 9.99999992e-10, 9.99999992e-10],\n",
       "        [7.69230769e-11, 1.25000000e-01, 1.25000000e-10, ...,\n",
       "         9.99999992e-10, 9.99999992e-10, 9.99999992e-10],\n",
       "        [7.69230769e-11, 1.25000000e-01, 1.25000000e-10, ...,\n",
       "         9.99999992e-10, 9.99999992e-10, 9.99999992e-10],\n",
       "        ...,\n",
       "        [7.69230769e-11, 1.25000000e-01, 1.25000000e-10, ...,\n",
       "         9.99999992e-10, 9.99999992e-10, 9.99999992e-10],\n",
       "        [7.69230769e-11, 1.25000000e-01, 1.25000000e-10, ...,\n",
       "         9.99999992e-10, 9.99999992e-10, 9.99999992e-10],\n",
       "        [7.69230769e-01, 1.25000000e-01, 9.99999999e-01, ...,\n",
       "         9.99999993e-01, 9.99999992e-10, 9.99999992e-10]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_conf_mats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the weights learned by the crowds layer for each annotator with their true confution matrices\n",
    "\n",
    "First, compute true confusion matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_conf_mats():\n",
    "    conf_mats = np.zeros((N_CLASSES,N_CLASSES,N_ANNOT)) + 0.00000001\n",
    "    num_answers = np.zeros((N_CLASSES,N_ANNOT)) + (0.00000001 * N_CLASSES)\n",
    "    for i in range(len(answers)):\n",
    "        for r in range(N_ANNOT):\n",
    "            if answers[i][r] != -1:\n",
    "                num_answers[labels_train[i],r] += 1\n",
    "                conf_mats[labels_train[i],answers[i][r],r] += 1\n",
    "    for r in range(N_ANNOT):\n",
    "        for c in range(N_CLASSES):\n",
    "            for c2 in range(N_CLASSES):\n",
    "                conf_mats[c,c2,r] = conf_mats[c,c2,r] / num_answers[c,r]\n",
    "    return conf_mats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function that make a visual comparison:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_conf_mats(true_conf_mat, weights):\n",
    "    # normalize weights matrix between 0 and 1\n",
    "    w_mat = (np.transpose(weights) + np.abs(weights.min()))\n",
    "    w_mat = w_mat / w_mat.max()\n",
    "    \n",
    "    sp1 = plt.subplot(1,2,1)\n",
    "    plt.imshow(true_conf_mat, interpolation='nearest', cmap=cm.YlOrRd)\n",
    "    plt.title(\"True\")\n",
    "\n",
    "    sp = plt.subplot(1,2,2)\n",
    "    plt.imshow(w_mat, interpolation='nearest', cmap=cm.YlOrRd)\n",
    "    plt.title(\"Estimated\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make comparison for various annotators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999999e-01, 8.33333333e-11, 8.33333333e-11, 8.33333333e-11,\n",
       "        8.33333333e-11, 8.33333333e-11, 8.33333333e-11, 8.33333333e-11],\n",
       "       [7.69230769e-11, 9.23076923e-01, 7.69230769e-11, 7.69230769e-11,\n",
       "        7.69230770e-02, 7.69230769e-11, 7.69230769e-11, 7.69230769e-11],\n",
       "       [1.11111111e-10, 1.11111111e-10, 7.77777777e-01, 1.11111111e-01,\n",
       "        1.11111111e-10, 1.11111111e-10, 1.11111111e-01, 1.11111111e-10],\n",
       "       [7.14285714e-11, 7.14285714e-11, 7.14285714e-11, 7.85714285e-01,\n",
       "        7.14285714e-11, 7.14285714e-11, 2.14285714e-01, 7.14285714e-11],\n",
       "       [5.00000000e-11, 5.00000000e-11, 5.00000000e-11, 5.00000000e-11,\n",
       "        1.00000000e+00, 5.00000000e-11, 5.00000000e-11, 5.00000000e-11],\n",
       "       [5.55555556e-02, 1.66666667e-01, 5.55555555e-11, 5.55555555e-11,\n",
       "        2.22222222e-01, 5.55555555e-01, 5.55555555e-11, 5.55555555e-11],\n",
       "       [1.11111111e-10, 1.11111111e-10, 1.11111111e-10, 2.22222222e-01,\n",
       "        1.11111111e-10, 1.11111111e-10, 7.77777777e-01, 1.11111111e-10],\n",
       "       [7.69230769e-11, 7.69230769e-11, 7.69230769e-11, 2.30769231e-01,\n",
       "        7.69230769e-11, 7.69230769e-11, 7.69230769e-11, 7.69230769e-01]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mats[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-c080a53a56fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_conf_mats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf_mats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,1], weights[0][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141369d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,2], weights[0][:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141545d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,9], weights[0][:,:,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBoBkCG4ASOZ/AY4lHMYRTHjNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1412d8d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,20], weights[0][:,:,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIBmCGwCS+V9eGgmYaJuWZwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14152d9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,23], weights[0][:,:,23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD1RJREFUeJzt3X2QnXV5xvHrypIUQoBE2bYkiyEUyghSBRY6DIoML0Ul\niB0Vw9uI04LTEYTCSMHOGCnqTNsREdthDAGkEl4UxBEG1DKIBKciIWA7JKbSEJogiRsIGF4D2bt/\nnGfrZkmy58DvOc+5k+9nZmfOOfvjfu7ZvXPx2+e8PI4IAQDymNB0AwCAzhDcAJAMwQ0AyRDcAJAM\nwQ0AyRDcAJAMwQ2gLbbfZ3tZ031sju2jbK9quo9uIbgLsv3CqK9h2y+Pun9a0/1h+2V7xZh5fMH2\nv4zz34TtfUbuR8TCiNivpv6+ZftLddTeFu3QdAPbkoiYMnLb9gpJfx0R92xpve0dIuL1bvQGSDpx\na/OIPNhxd5HtL9m+xfZNttdLOt32Dba/OGrNsVXoj9wfsH277SHbT9j+TAOtYxtlex/bP7X9vO21\ntm+pHr+/WvLLanf+ibGnI6pd/Ods/6ftF21fY/uPbN9te73te2xPG7X+u7ZXV8e63/YB1eNnSzpN\n0kXVse6oHp9u+7ZRs//ZUbV2qnbp62wvkXRo/T+t3kFwd99fSrpR0m6SbtnaQtsTJN0p6SFJMyQd\nJ+lzto+pu0lsNy6T9GNJ0yQNSPqGJEXEkdX33x0RUyJiS7P6UbXm8k8lnSjpbkmfl9SvVr58dtTa\nuyXtK+kPJS2WtKA61rzq9j9Vxzqxmv07JP1Srdk/RtL5to+vas2V9CfV1/GSPvkWfgbpENzd90BE\n3BERwxHx8jhrD5e0a0R8JSI2RMTjkq6RNKf+NrEN+r7t50Z9nSXpNUkzJU2PiFci4oEOa34jItZE\nxFOSFkp6MCIeiYhXJN0u6aCRhRFxbUSsj4hXJX1R0rtt77aFuodK6o+If6hmf7mkq/X72T9Z0pcj\n4tmIWCnpyg77To1z3N23soO1MyW9w/Zzox7rk3Rf0Y6wvfjI2HPc1WmJyyT9wvY6SV+NiGs7qLlm\n1O2XN3N/SnWcPklflvRxtXbjw9Wa3SU9v5m6MyVN38zsL6xuT9em/5ae7KDn9Aju7hv7cYwvSpo8\n6v4fj7q9UtKvI+KdtXeF7VJErJZ0liTZfq+ke2zfX/11V9Kpkk6SdKykFWqdKlwnySOtjFm/UtIT\nEbHvFuo9LWlPSY9V999Rstlex6mS5j0q6QTb02zvoU3PCf6HpA22L7S9o+0+2wfaPqSZVrGtsf1x\n2wPV3XVqBejIbniNpL0LHWoXSa9KekatjcpXxnx/7LF+IWm97b+rnojss/0u2yNPQn5H0iXVv5sB\nSecW6jMFgrt535K0VK0/9X4o6eaRb1QvFfyQpMPU2qWslfRNSbt2u0lsE+4Y8zru29U6l/yg7Rck\n/UDSedX5ZKl1Hvr66nz4yW/x2P+m1ow/JWmJpJ+P+f41kvavjvX9iNgoabak90h6Qq3Zn6/WTl2S\nLq3qPaHWk6vffov9pWIupAAAubDjBoBkCG4ASIbgBoBkCG4ASIbgBoBkankDzmT3xVRNLFJr+iGl\nXkaKbcWKFb/R2rXPefyVZRWd6/2mjL+oXZN2LFfLBfdyw6+VqyVJr4z3CREd2HlquVqFXpm3YuUz\nWvvsC23NdS3BPVUT9WnNLFJr7qLt6uWZaMPg4BmNHLfkXH9h/uFF6kiSZh5QrlbfpHK1Xlwz/ppO\nLHts/DXt+vPZ5WptLPM/qEOP/8e213KqBACSIbgBIBmCGwCSIbgBIJm2gtv2B2wvs/247Yvrbgro\nBuYaWY0b3NUHoP+rpA9K2l/SKbb3r7sxoE7MNTJrZ8d9mKTHI2J5RGxQ62NHT6q3LaB2zDXSaie4\nZ2jTSwStqh7bhO2zbS+yveglbSzVH1AX5hppFXtyMiLmRcRgRAxOVl+pskCjmGv0onaC+ym1ru02\nYqB6DMiMuUZa7QT3Q5L2tT3L9iRJc9S6xBGQGXONtMb9rJKIeN32OZJ+JKlP0rURUfBDA4DuY66R\nWVsfMhURd0m6q+ZegK5irpEV75wEgGQIbgBIhuAGgGRquZDC9EP2LnYBhI1/c1aROpLUd9XVxWqV\nFEOLyxZc+UixUj74r4rVym76we/Q3J9dWaTW8pnl5nrvNecWq6UN64uV2nj93xerJUkb73+2WK1J\nsw8uVqvYlX4mTm57KTtuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaA\nZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaAZGq5dFlJJS83Nnz5+cVqlTThgivK\nFuwveFkm/N6zqzX83a8WKTXr/jlF6kjSj31qsVrHXj1QrNaET/xFsVqSNOFjrxarFSvvLVZLMVym\nTgeXjWPHDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkMy4wW17T9s/sb3E9mO2z+tGY0DdmG1k1c7r\nuF+XdGFELLa9i6SHbf97RCypuTegbsw2Uhp3xx0RT0fE4ur2eklLJc2ouzGgbsw2suroHLftvSQd\nJOnBzXzvbNuLbC8aGlpXpjugS7Y025vM9frXmmgNeIO2g9v2FEm3STo/In439vsRMS8iBiNisL9/\nWskegVptbbY3metdJjbTIDBGW8Fte6Jag70gIr5Xb0tA9zDbyKidV5VY0jWSlkbE5fW3BHQHs42s\n2tlxHyHpDElH2360+vpQzX0B3cBsI6VxXw4YEQ9Ichd6AbqK2UZWvHMSAJIhuAEgGYIbAJLp+UuX\nlVTyEmFxHy9C6NQL7zulSJ3hZf9bpE7Hdt1NPvqDZWr1/UGZOpKO+81nitVadcg/F6s1cFK5y7NJ\nklzu6Qj37Vis1ssfvaxIneEVa9tey44bAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEg\nGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgme3q0mUl+agLitW6\n1KcWqyVJc+PGovVKmbLwpiJ1JgyeUaROx4bWaXj+d4qU8p+9rUgdSZpw0txitfZcfm2xWjftdE6x\nWpI058kzyxUbOKZYqZ3u+XaROhMO+2T7a4scEQDQNQQ3ACRDcANAMgQ3ACRDcANAMgQ3ACTTdnDb\n7rP9iO0762wI6CbmGhl1suM+T9LSuhoBGsJcI522gtv2gKQTJM2vtx2ge5hrZNXujvsKSRdJGt7S\nAttn215ke9HQ0LoizQE162yuX3qte50BWzFucNueLem3EfHw1tZFxLyIGIyIwf7+acUaBOrwpuZ6\n8sQudQdsXTs77iMkfdj2Ckk3Szra9g21dgXUj7lGWuMGd0RcEhEDEbGXpDmS7o2I02vvDKgRc43M\neB03ACTT0ce6RsR9ku6rpROgIcw1smHHDQDJENwAkAzBDQDJENwAkEw915zc+Ir03LJaSr8lU/dr\nuoPN+sL/lL3m5Ma//XSxWn1f+2axWum9fVdNOO3YIqXiZz8vUkeSZJer1TepWKmTz5lSrJYk/XSv\n64rVOmpjmd+jJCmiXK02seMGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQI\nbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIhuAGgGQIbgBIpp5Ll/Xt2LOXCSvlUpe73Njc\nuLFYLUnq+9rsovUwIqR4vUglH1fudxTL7yhWa9GBC4rVGvz1OcVqSdL7Ly5XKxZeWa7YjFll6rz6\nfNtL2XEDQDIENwAkQ3ADQDIENwAkQ3ADQDJtBbftqbZvtf0r20ttH153Y0A3MNvIqN2XA35d0g8j\n4mO2J0maXGNPQDcx20hn3OC2vZukIyWdKUkRsUHShnrbAurHbCOrdk6VzJI0JOk624/Ynm9757GL\nbJ9te5HtRUND64o3CtRg3NneZK6ffamZLoEx2gnuHSQdLOmqiDhI0ouS3vAepoiYFxGDETHY3z+t\ncJtALcad7U3m+m2cRUFvaCe4V0laFREPVvdvVWvYgeyYbaQ0bnBHxGpJK22PfPjIMZKW1NoV0AXM\nNrJq91Ul50paUD3rvlzSp+prCegqZhvptBXcEfGopMGaewG6jtlGRrxzEgCSIbgBIBmCGwCSIbgB\nIJl6Ll22HbjwvdF0C+nEfZeXKbR+TZk6nZq4izzw/iKl4qXVRepIkt/+rmK19nlnuUuXefcDi9Wq\nKpYr1f+eYqVWH3BmkTqvrXym7bXsuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIh\nuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJJxRPlLcNkekvTkOMt2\nl7S2+MHfOvrqTBN9zYyI/i4fs925lvhddYq+Wtqe61qCu60D24siYrCRg28FfXWmV/tqUq/+TOir\nM73al8SpEgBIh+AGgGSaDO55DR57a+irM73aV5N69WdCX53p1b6aO8cNAHhzOFUCAMk0Ety2P2B7\nme3HbV/cRA9j2d7T9k9sL7H9mO3zmu5phO0+24/YvrPpXkazPdX2rbZ/ZXup7cOb7qlJzHXnenG2\nM8x110+V2O6T9N+SjpO0StJDkk6JiCVdbeSNfe0haY+IWGx7F0kPS/pI031Jku0LJA1K2jUiZjfd\nzwjb10taGBHzbU+SNDkinmu6ryYw129OL852hrluYsd9mKTHI2J5RGyQdLOkkxroYxMR8XRELK5u\nr5e0VNKMZruSbA9IOkHS/KZ7Gc32bpKOlHSNJEXEhl4b7i5jrjvUi7OdZa6bCO4ZklaOur9KPTJI\nI2zvJekgSQ8224kk6QpJF0kabrqRMWZJGpJ0XfWn7nzbOzfdVIOY68714mynmGuenBzD9hRJt0k6\nPyJ+13AvsyX9NiIebrKPLdhB0sGSroqIgyS9KKknzuvijXpprqt+enW2U8x1E8H9lKQ9R90fqB5r\nnO2Jag33goj4XtP9SDpC0odtr1DrT++jbd/QbEv/b5WkVRExsnu7Va2B314x153p1dlOMddNBPdD\nkva1Pas68T9H0g8a6GMTtq3Wea2lEXF50/1IUkRcEhEDEbGXWj+neyPi9IbbkiRFxGpJK23vVz10\njKSeeMKrIcx1B3p1trPM9Q7dPmBEvG77HEk/ktQn6dqIeKzbfWzGEZLOkPRfth+tHvt8RNzVYE+9\n7lxJC6qgWi7pUw330xjmepvS83PNOycBIBmenASAZAhuAEiG4AaAZAhuAEiG4AaAZAhuAEiG4AaA\nZAhuAEjm/wDugxEZTfjErgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13fc160b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,30], weights[0][:,:,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMxmi4frCkgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x141702978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,36], weights[0][:,:,36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZP4X0+MNpyj2nY0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1417f0a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,39], weights[0][:,:,39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14132d908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,45], weights[0][:,:,45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1417ddd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,56], weights[0][:,:,56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADHCAYAAAA5xrkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13a2d7a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_conf_mats(conf_mats[:,:,58], weights[0][:,:,58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
