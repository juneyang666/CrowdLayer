{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yajingyang/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, merge, Reshape, Permute, Multiply, Dot,dot, Concatenate, Add\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import keras as keras\n",
    "\n",
    "# packages for learning from crowds\n",
    "from crowd_layer.crowd_layers import CrowdsClassification, MaskedMultiCrossEntropy, CrowdsClassificationSModel, \\\n",
    "    CrowdsClassificationCModelSingleWeight, CrowdsClassificationCModel, MaskedMultiCrossEntropyCosSim, \\\n",
    "    MaskedMultiCrossEntropyBaseChannel, MaskedMultiCrossEntropyBaseChannelConst, CrowdsClassificationSModelChannelMatrix, \\\n",
    "    MaskedMultiCrossEntropyCurriculumChannelMatrix\n",
    "from crowd_layer.crowd_aggregators import CrowdsCategoricalAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevent tensorflow from allocating the entire GPU memory at once\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "def load_data(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = np.load(f)\n",
    "    f.close()\n",
    "    return data\n",
    "\n",
    "def one_hot(target, n_classes):\n",
    "    targets = np.array([target]).reshape(-1)\n",
    "    one_hot_targets = np.eye(n_classes)[targets]\n",
    "    return one_hot_targets\n",
    "\n",
    "def get_data(DATA_PATH, N_CLASSES):\n",
    "    \n",
    "    print(\"\\nLoading train data...\")\n",
    "    # images processed by VGG16\n",
    "    data_train_vgg16 = load_data(DATA_PATH+\"data_train_vgg16.npy\")\n",
    "    print(data_train_vgg16.shape)\n",
    "\n",
    "    # ground truth labels\n",
    "    labels_train = load_data(DATA_PATH+\"labels_train.npy\")\n",
    "    print(labels_train.shape)\n",
    "\n",
    "    # labels obtained from majority voting\n",
    "    labels_train_mv = load_data(DATA_PATH+\"labels_train_mv.npy\")\n",
    "    print(labels_train_mv.shape)\n",
    "\n",
    "#     # labels obtained by using the approach by Dawid and Skene\n",
    "#     labels_train_ds = load_data(DATA_PATH+\"labels_train_DS.npy\")\n",
    "#     print(labels_train_ds.shape)\n",
    "\n",
    "    # data from Amazon Mechanical Turk\n",
    "    print(\"\\nLoading AMT data...\")\n",
    "    answers = load_data(DATA_PATH+\"answers.npy\")\n",
    "    print(answers.shape)\n",
    "    N_ANNOT = answers.shape[1]\n",
    "    print(\"N_CLASSES:\", N_CLASSES)\n",
    "    print(\"N_ANNOT:\", N_ANNOT)\n",
    "\n",
    "    # load test data\n",
    "    print(\"\\nLoading test data...\")\n",
    "\n",
    "    # images processed by VGG16\n",
    "    data_test_vgg16 = load_data(DATA_PATH+\"data_test_vgg16.npy\")\n",
    "    print(data_test_vgg16.shape)\n",
    "\n",
    "    # test labels\n",
    "    labels_test = load_data(DATA_PATH+\"labels_test.npy\")\n",
    "    print(labels_test.shape)\n",
    "\n",
    "    print(\"\\nLoading validation data...\")\n",
    "    # images processed by VGG16\n",
    "    data_valid_vgg16 = load_data(DATA_PATH+\"data_valid_vgg16.npy\")\n",
    "    print(data_valid_vgg16.shape)\n",
    "\n",
    "    # validation labels\n",
    "    labels_valid = load_data(DATA_PATH+\"labels_valid.npy\")\n",
    "    print(labels_valid.shape)\n",
    "\n",
    "    labels_train_bin = one_hot(labels_train, N_CLASSES)\n",
    "    labels_train_mv_bin = one_hot(labels_train_mv, N_CLASSES)\n",
    "#     labels_train_ds_bin = one_hot(labels_train_ds, N_CLASSES)\n",
    "#     print(labels_train_ds_bin.shape)\n",
    "    labels_test_bin = one_hot(labels_test, N_CLASSES)\n",
    "    labels_valid_bin = one_hot(labels_valid, N_CLASSES)\n",
    "\n",
    "\n",
    "    answers_bin_missings = []\n",
    "    for i in range(len(answers)):\n",
    "        row = []\n",
    "        for r in range(N_ANNOT):\n",
    "            if answers[i,r] == -1:\n",
    "                row.append(-1 * np.ones(N_CLASSES))\n",
    "            else:\n",
    "                row.append(one_hot(answers[i,r], N_CLASSES)[0,:])\n",
    "        answers_bin_missings.append(row)\n",
    "    answers_bin_missings = np.array(answers_bin_missings).swapaxes(1,2)\n",
    "\n",
    "    answers_test_bin_missings = np.zeros((len(labels_test), N_CLASSES))\n",
    "    answers_test_bin_missings[np.arange(len(labels_test)), labels_test] = 1\n",
    "    answers_test_bin_missings = np.repeat(answers_test_bin_missings.reshape([len(labels_test),N_CLASSES,1]), N_ANNOT, axis=2)\n",
    "\n",
    "    answers_valid_bin_missings = np.zeros((len(labels_valid), N_CLASSES))\n",
    "    answers_valid_bin_missings[np.arange(len(labels_valid)), labels_valid] = 1\n",
    "    answers_valid_bin_missings = np.repeat(answers_valid_bin_missings.reshape([len(labels_valid),N_CLASSES,1]), N_ANNOT, axis=2)\n",
    "    \n",
    "    x = {'train': data_train_vgg16, 'test': data_test_vgg16, 'val': data_valid_vgg16}\n",
    "    y_gt = {'train': labels_train_bin, 'test': labels_test_bin, 'val': labels_valid_bin}\n",
    "    y_annot = {'train': answers_bin_missings, 'test': answers_test_bin_missings, 'val': answers_valid_bin_missings, 'mv':labels_train_mv_bin}\n",
    "    return x, y_gt, y_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def eval(model,x_test, y_test):\n",
    "    print('Test dataset results: ')\n",
    "    print(dict(zip(model.metrics_names,model.evaluate(x_test,y_test, verbose=False))))\n",
    "\n",
    "\n",
    "def get_trace(model):\n",
    "\n",
    "    channel_matrix = model.get_weights()[-1]\n",
    "    channel_matrix_trace = tf.trace(K.permute_dimensions(channel_matrix, [2, 0, 1]))\n",
    "    channel_matrix_trace_arr = K.eval(channel_matrix_trace)\n",
    "    return channel_matrix_trace_arr\n",
    "\n",
    "\n",
    "def print_single_loss(model):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # list all data in history\n",
    "    print(model.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model.history['baseline_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(model.history['baseline_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_history(df, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # Make a data frame\n",
    "    df['x'] = range(df.shape[0])\n",
    "\n",
    "    # style\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "    # create a color palette\n",
    "    palette = plt.get_cmap('Set1')\n",
    "\n",
    "    # multiple line plot\n",
    "    num = 0\n",
    "    for column in df.drop('x', axis=1):\n",
    "        num += 1\n",
    "        plt.plot(df['x'], df[column], marker='', color=palette(num), linewidth=1, alpha=0.9, label=column)\n",
    "\n",
    "    # Add legend\n",
    "    plt.legend(loc=2, ncol=2)\n",
    "\n",
    "    # Add titles\n",
    "    plt.title(title, loc='left', fontsize=12, fontweight=0, color='orange')\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.savefig(title+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_model(train_data_shape, N_CLASSES):\n",
    "    base_model = Sequential()\n",
    "    base_model.add(Flatten(input_shape=train_data_shape[1:]))\n",
    "    base_model.add(Dense(128, activation='relu'))\n",
    "    base_model.add(Dropout(0.4))\n",
    "    base_model.add(Dense(64, activation='relu'))\n",
    "    base_model.add(Dropout(0.4))\n",
    "    base_model.add(Dense(N_CLASSES))\n",
    "    base_model.add(Activation(\"softmax\"))\n",
    "    base_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def majority_vote(x, y_gt, y_annot, N_CLASSES):\n",
    "    train_data_shape = x['train'].shape\n",
    "    N_ANNOT = y_annot['train'].shape[2]\n",
    "    baseline_model = build_base_model(train_data_shape, N_CLASSES)\n",
    "\n",
    "#     eval(baseline_model, x['test'], y_test=y_gt['test'])\n",
    "    history = baseline_model.fit(x['train'], y_annot['mv'], epochs=N_EPOCHS, shuffle=True,\n",
    "                              batch_size=BATCH_SIZE, verbose=0)\n",
    "    eval(baseline_model, x['test'], y_test=y_gt['test'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_gt(x, y_gt, N_CLASSES):\n",
    "    train_data_shape = x['train'].shape\n",
    "    baseline_model = build_base_model(train_data_shape, N_CLASSES)\n",
    "\n",
    "#     eval(baseline_model, x['test'], y_test=y_gt['test'])\n",
    "    history = baseline_model.fit(x['train'], y_gt['train'], epochs=N_EPOCHS, shuffle=True,\n",
    "                                 batch_size=BATCH_SIZE, verbose=0)\n",
    "    eval(baseline_model, x['test'], y_test=y_gt['test'])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_crowd_model(train_data_shape, N_CLASSES, N_ANNOT, softmax, trace):\n",
    "    hidden_layers = Sequential()\n",
    "    hidden_layers.add(Flatten(input_shape=train_data_shape[1:]))\n",
    "    hidden_layers.add(Dense(128, activation='relu'))\n",
    "    hidden_layers.add(Dropout(0.4))\n",
    "    hidden_layers.add(Dense(64, activation='relu'))\n",
    "    hidden_layers.add(Dropout(0.4))\n",
    "\n",
    "    train_inputs = Input(shape=(train_data_shape[1:]))\n",
    "    last_hidden = hidden_layers(train_inputs)\n",
    "    baseline_output = Dense(N_CLASSES, activation='softmax', name='baseline')(last_hidden)\n",
    "\n",
    "    if softmax:\n",
    "        channel_layer = CrowdsClassificationSModelChannelMatrix(N_CLASSES, N_ANNOT)\n",
    "        channeled_output = channel_layer([last_hidden, baseline_output])\n",
    "    else:\n",
    "        channel_layer = CrowdsClassification(N_CLASSES, N_ANNOT)\n",
    "        channeled_output = channel_layer(baseline_output)\n",
    "\n",
    "\n",
    "\n",
    "    model = Model(inputs=train_inputs, outputs=[channeled_output, baseline_output])\n",
    "\n",
    "    if trace:\n",
    "        loss = MaskedMultiCrossEntropyCurriculumChannelMatrix(model, 1, 1).loss\n",
    "    else:\n",
    "        loss = MaskedMultiCrossEntropy().loss\n",
    "\n",
    "    # compile model with masked loss and train\n",
    "    model.compile(optimizer='adam',\n",
    "                         loss=[loss, 'categorical_crossentropy'],\n",
    "                         loss_weights=[1, 0],\n",
    "                         metrics=['accuracy']\n",
    "                        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowd_model(x, y_gt, y_annot, N_CLASSES, softmax, trace):\n",
    "    train_data_shape = x['train'].shape\n",
    "    N_ANNOT = y_annot['train'].shape[2]\n",
    "\n",
    "    model = build_base_crowd_model(train_data_shape, N_CLASSES, N_ANNOT, softmax, trace)    \n",
    "    \n",
    "    history = model.fit(x['train'], [y_annot['train'], y_gt['train']], epochs=N_EPOCHS, shuffle=True,\n",
    "                              batch_size=BATCH_SIZE, verbose=0)\n",
    "    trace_arr = get_trace(model)\n",
    "    eval(model, x['test'], y_test=[y_annot['test'], y_gt['test']])\n",
    "    return history, trace_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with LabelMe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(10000, 4, 4, 512)\n",
      "(10000,)\n",
      "(10000,)\n",
      "\n",
      "Loading AMT data...\n",
      "(10000, 59)\n",
      "N_CLASSES: 8\n",
      "N_ANNOT: 59\n",
      "\n",
      "Loading test data...\n",
      "(1188, 4, 4, 512)\n",
      "(1188,)\n",
      "\n",
      "Loading validation data...\n",
      "(500, 4, 4, 512)\n",
      "(500,)\n",
      "\n",
      "Crowd noise adaptation model with softmax: False, trace: False\n",
      "Tensor(\"baseline_11/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_9/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_9/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_9_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_9/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9748115021773059, 'crowds_classification_9_loss': 0.9748115021773059, 'baseline_loss': 2.425109326574083, 'crowds_classification_9_acc': 0.020412457912457913, 'baseline_acc': 0.7777777777777778}\n",
      "Tensor(\"baseline_12/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_10/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_10/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_10_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_10/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9809352295968669, 'crowds_classification_10_loss': 0.9809352295968669, 'baseline_loss': 1.2295285197420152, 'crowds_classification_10_acc': 0.03545875420875421, 'baseline_acc': 0.8173400673400674}\n",
      "Tensor(\"baseline_13/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_11/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_11/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_11_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_11/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9455150080851031, 'crowds_classification_11_loss': 0.9455150080851031, 'baseline_loss': 1.0378686160488864, 'crowds_classification_11_acc': 0.020412457912457913, 'baseline_acc': 0.8316498316498316}\n",
      "Tensor(\"baseline_14/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_12/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_12/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_12_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_12/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9495919643829166, 'crowds_classification_12_loss': 0.9495919643829166, 'baseline_loss': 1.0949379488173558, 'crowds_classification_12_acc': 0.03398569023569024, 'baseline_acc': 0.8333333333333334}\n",
      "Tensor(\"baseline_15/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_13/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_13/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_13_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_13/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.8965996947352733, 'crowds_classification_13_loss': 0.8965996947352733, 'baseline_loss': 0.8777202931389538, 'crowds_classification_13_acc': 0.04177188552188552, 'baseline_acc': 0.8535353535353535}\n",
      "Tensor(\"baseline_16/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_14/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_14/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_14_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_14/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9405892898739387, 'crowds_classification_14_loss': 0.9405892898739387, 'baseline_loss': 1.1563783224095099, 'crowds_classification_14_acc': 0.03398569023569024, 'baseline_acc': 0.8392255892255892}\n",
      "Tensor(\"baseline_17/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_15/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_15/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_15_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_15/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.0699423435159805, 'crowds_classification_15_loss': 1.0699423435159805, 'baseline_loss': 2.9025160950241666, 'crowds_classification_15_acc': 0.021780303030303032, 'baseline_acc': 0.7297979797979798}\n",
      "Tensor(\"baseline_18/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_16/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_16/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_16_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_16/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9527842823905174, 'crowds_classification_16_loss': 0.9527842823905174, 'baseline_loss': 1.0753356019107105, 'crowds_classification_16_acc': 0.03651094276094276, 'baseline_acc': 0.8274410774410774}\n",
      "Tensor(\"baseline_19/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_17/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_17/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_17_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_17/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.932359799792871, 'crowds_classification_17_loss': 0.932359799792871, 'baseline_loss': 1.0284001715794857, 'crowds_classification_17_acc': 0.04177188552188552, 'baseline_acc': 0.8375420875420876}\n",
      "Tensor(\"baseline_20/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_18/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_18/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_18_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_18/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9762975336726667, 'crowds_classification_18_loss': 0.9762975336726667, 'baseline_loss': 1.1923484599801024, 'crowds_classification_18_acc': 0.022832491582491583, 'baseline_acc': 0.8215488215488216}\n",
      "Tensor(\"baseline_21/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_19/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_19/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_19_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_19/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9467084357634137, 'crowds_classification_19_loss': 0.9467084357634137, 'baseline_loss': 1.15588749496122, 'crowds_classification_19_acc': 0.0333543771043771, 'baseline_acc': 0.8375420875420876}\n",
      "Tensor(\"baseline_22/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_20/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_20/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_20_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_20/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9204113664049091, 'crowds_classification_20_loss': 0.9204113664049091, 'baseline_loss': 0.9291235884582555, 'crowds_classification_20_acc': 0.041035353535353536, 'baseline_acc': 0.8392255892255892}\n",
      "Tensor(\"baseline_23/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_21/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_21/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_21_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_21/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset results: \n",
      "{'loss': 0.9087348490050344, 'crowds_classification_21_loss': 0.9087348490050344, 'baseline_loss': 0.9182419966065923, 'crowds_classification_21_acc': 0.030303030303030304, 'baseline_acc': 0.8484848484848485}\n",
      "Tensor(\"baseline_24/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_22/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_22/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_22_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_22/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9305717415279813, 'crowds_classification_22_loss': 0.9305717415279813, 'baseline_loss': 0.9502164366896506, 'crowds_classification_22_acc': 0.032196969696969696, 'baseline_acc': 0.8417508417508418}\n",
      "Tensor(\"baseline_25/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_23/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_23/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_23_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_23/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9132569763395522, 'crowds_classification_23_loss': 0.9132569763395522, 'baseline_loss': 0.9103255415780577, 'crowds_classification_23_acc': 0.034406565656565656, 'baseline_acc': 0.8434343434343434}\n",
      "Tensor(\"baseline_26/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_24/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_24/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_24_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_24/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9507130109501206, 'crowds_classification_24_loss': 0.9507130109501206, 'baseline_loss': 1.1174547761515636, 'crowds_classification_24_acc': 0.037247474747474744, 'baseline_acc': 0.82996632996633}\n",
      "Tensor(\"baseline_27/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_25/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_25/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_25_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_25/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.0409659988149649, 'crowds_classification_25_loss': 1.0409659988149649, 'baseline_loss': 2.5660773612784618, 'crowds_classification_25_acc': 0.022832491582491583, 'baseline_acc': 0.7508417508417509}\n",
      "Tensor(\"baseline_28/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_26/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_26/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_26_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_26/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.0522183569192083, 'crowds_classification_26_loss': 1.0522183569192083, 'baseline_loss': 2.9114344734134097, 'crowds_classification_26_acc': 0.02135942760942761, 'baseline_acc': 0.7264309764309764}\n",
      "Tensor(\"baseline_29/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_27/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_27/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_27_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_27/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 0.9432515459831314, 'crowds_classification_27_loss': 0.9432515459831314, 'baseline_loss': 0.9667110851266568, 'crowds_classification_27_acc': 0.030934343434343436, 'baseline_acc': 0.8425925925925926}\n",
      "Tensor(\"baseline_30/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_28/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_28/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "y_true:  Tensor(\"crowds_classification_28_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_28/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.0081561506797971, 'crowds_classification_28_loss': 1.0081561506797971, 'baseline_loss': 2.6084071880689375, 'crowds_classification_28_acc': 0.029356060606060608, 'baseline_acc': 0.7643097643097643}\n",
      "\n",
      "Crowd noise adaptation model with softmax: False, trace: True\n",
      "Tensor(\"baseline_31/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_29/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_29/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.060833312846996, 'crowds_classification_29_loss': -7.060833312846996, 'baseline_loss': 1.108063727466747, 'crowds_classification_29_acc': 0.03188131313131313, 'baseline_acc': 0.8400673400673401}\n",
      "Tensor(\"baseline_32/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_30/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_30/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.036723082314436, 'crowds_classification_30_loss': -7.036723082314436, 'baseline_loss': 1.0362486633588168, 'crowds_classification_30_acc': 0.03198653198653199, 'baseline_acc': 0.82996632996633}\n",
      "Tensor(\"baseline_33/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_31/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_31/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.0269484182800905, 'crowds_classification_31_loss': -7.0269484182800905, 'baseline_loss': 1.0895052425789111, 'crowds_classification_31_acc': 0.04429713804713805, 'baseline_acc': 0.8156565656565656}\n",
      "Tensor(\"baseline_34/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_32/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_32/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.0380843143270475, 'crowds_classification_32_loss': -7.0380843143270475, 'baseline_loss': 1.134505263771172, 'crowds_classification_32_acc': 0.04198232323232323, 'baseline_acc': 0.8316498316498316}\n",
      "Tensor(\"baseline_35/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_33/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_33/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.0677262572728425, 'crowds_classification_33_loss': -7.0677262572728425, 'baseline_loss': 1.0067023665390231, 'crowds_classification_33_acc': 0.03103956228956229, 'baseline_acc': 0.8324915824915825}\n",
      "Tensor(\"baseline_36/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_34/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_34/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.026062016535287, 'crowds_classification_34_loss': -7.026062016535287, 'baseline_loss': 1.270755850104772, 'crowds_classification_34_acc': 0.032091750841750845, 'baseline_acc': 0.819023569023569}\n",
      "Tensor(\"baseline_37/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_35/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_35/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.0474807935130315, 'crowds_classification_35_loss': -7.0474807935130315, 'baseline_loss': 1.0374825137733208, 'crowds_classification_35_acc': 0.03493265993265993, 'baseline_acc': 0.82996632996633}\n",
      "Tensor(\"baseline_38/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_36/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_36/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.069947496407763, 'crowds_classification_36_loss': -7.069947496407763, 'baseline_loss': 1.004657715257972, 'crowds_classification_36_acc': 0.030934343434343436, 'baseline_acc': 0.8375420875420876}\n",
      "Tensor(\"baseline_39/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_37/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_37/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.067775499941122, 'crowds_classification_37_loss': -7.067775499941122, 'baseline_loss': 1.0768193518774276, 'crowds_classification_37_acc': 0.032407407407407406, 'baseline_acc': 0.8358585858585859}\n",
      "Tensor(\"baseline_40/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_38/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_38/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.000940467372085, 'crowds_classification_38_loss': -7.000940467372085, 'baseline_loss': 2.399778557332979, 'crowds_classification_38_acc': 0.02199074074074074, 'baseline_acc': 0.7702020202020202}\n",
      "Tensor(\"baseline_41/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_39/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_39/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.05868475204365, 'crowds_classification_39_loss': -7.05868475204365, 'baseline_loss': 1.0987895819474551, 'crowds_classification_39_acc': 0.012415824915824917, 'baseline_acc': 0.8324915824915825}\n",
      "Tensor(\"baseline_42/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_40/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_40/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -6.962201230855101, 'crowds_classification_40_loss': -6.962201230855101, 'baseline_loss': 3.1419910516602423, 'crowds_classification_40_acc': 0.020202020202020204, 'baseline_acc': 0.7070707070707071}\n",
      "Tensor(\"baseline_43/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_41/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_41/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.040155627510765, 'crowds_classification_41_loss': -7.040155627510765, 'baseline_loss': 1.1325244657955562, 'crowds_classification_41_acc': 0.02199074074074074, 'baseline_acc': 0.8341750841750841}\n",
      "Tensor(\"baseline_44/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_42/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_42/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.052336124458698, 'crowds_classification_42_loss': -7.052336124458698, 'baseline_loss': 1.13069224013925, 'crowds_classification_42_acc': 0.0422979797979798, 'baseline_acc': 0.8358585858585859}\n",
      "Tensor(\"baseline_45/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_43/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_43/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.03360912053272, 'crowds_classification_43_loss': -7.03360912053272, 'baseline_loss': 1.2324992102203947, 'crowds_classification_43_acc': 0.02988215488215488, 'baseline_acc': 0.8274410774410774}\n",
      "Tensor(\"baseline_46/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_44/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_44/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.051281845529473, 'crowds_classification_44_loss': -7.051281845529473, 'baseline_loss': 1.1068153010574655, 'crowds_classification_44_acc': 0.032302188552188554, 'baseline_acc': 0.8333333333333334}\n",
      "Tensor(\"baseline_47/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_45/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_45/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.031705207696266, 'crowds_classification_45_loss': -7.031705207696266, 'baseline_loss': 1.183055543400322, 'crowds_classification_45_acc': 0.029987373737373736, 'baseline_acc': 0.8316498316498316}\n",
      "Tensor(\"baseline_48/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_46/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_46/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.015506654476076, 'crowds_classification_46_loss': -7.015506654476076, 'baseline_loss': 1.3984345175100095, 'crowds_classification_46_acc': 0.030303030303030304, 'baseline_acc': 0.8198653198653199}\n",
      "Tensor(\"baseline_49/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_47/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_47/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.092904652810659, 'crowds_classification_47_loss': -7.092904652810659, 'baseline_loss': 0.955578393569398, 'crowds_classification_47_acc': 0.022622053872053873, 'baseline_acc': 0.8619528619528619}\n",
      "Tensor(\"baseline_50/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_48/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_48/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': -7.077560675264609, 'crowds_classification_48_loss': -7.077560675264609, 'baseline_loss': 0.9370673731477424, 'crowds_classification_48_acc': 0.03177609427609428, 'baseline_acc': 0.8434343434343434}\n",
      "\n",
      "Crowd noise adaptation model with softmax: True, trace: False\n",
      "inputs:  [<tf.Tensor 'sequential_98/dropout_196/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_51/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_4/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_4_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_4/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.626902820285322, 'crowds_classification_s_model_channel_matrix_4_loss': 1.626902820285322, 'baseline_loss': 1.80952136444323, 'crowds_classification_s_model_channel_matrix_4_acc': 0.008101851851851851, 'baseline_acc': 0.8240740740740741}\n",
      "inputs:  [<tf.Tensor 'sequential_99/dropout_198/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_52/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_5/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_5_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_5/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6179916850645535, 'crowds_classification_s_model_channel_matrix_5_loss': 1.6179916850645535, 'baseline_loss': 1.6848523842565941, 'crowds_classification_s_model_channel_matrix_5_acc': 0.012836700336700337, 'baseline_acc': 0.8324915824915825}\n",
      "inputs:  [<tf.Tensor 'sequential_100/dropout_200/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_53/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_6/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_6_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_6/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.615156403695694, 'crowds_classification_s_model_channel_matrix_6_loss': 1.615156403695694, 'baseline_loss': 1.906257308780635, 'crowds_classification_s_model_channel_matrix_6_acc': 0.019255050505050504, 'baseline_acc': 0.8240740740740741}\n",
      "inputs:  [<tf.Tensor 'sequential_101/dropout_202/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_54/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_7/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_7_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_7/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.61709340092309, 'crowds_classification_s_model_channel_matrix_7_loss': 1.61709340092309, 'baseline_loss': 1.81374021151702, 'crowds_classification_s_model_channel_matrix_7_acc': 0.017992424242424244, 'baseline_acc': 0.8291245791245792}\n",
      "inputs:  [<tf.Tensor 'sequential_102/dropout_204/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_55/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_8/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_8_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_8/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.613263513504054, 'crowds_classification_s_model_channel_matrix_8_loss': 1.613263513504054, 'baseline_loss': 1.7513497087896546, 'crowds_classification_s_model_channel_matrix_8_acc': 0.01778198653198653, 'baseline_acc': 0.8316498316498316}\n",
      "inputs:  [<tf.Tensor 'sequential_103/dropout_206/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_56/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_9/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_9_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_9/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.612204119412586, 'crowds_classification_s_model_channel_matrix_9_loss': 1.612204119412586, 'baseline_loss': 1.7777250063801984, 'crowds_classification_s_model_channel_matrix_9_acc': 0.014625420875420875, 'baseline_acc': 0.8324915824915825}\n",
      "inputs:  [<tf.Tensor 'sequential_104/dropout_208/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_57/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_10/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_10_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_10/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6165464028766259, 'crowds_classification_s_model_channel_matrix_10_loss': 1.6165464028766259, 'baseline_loss': 1.7946807972911232, 'crowds_classification_s_model_channel_matrix_10_acc': 0.008312289562289563, 'baseline_acc': 0.8249158249158249}\n",
      "inputs:  [<tf.Tensor 'sequential_105/dropout_210/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_58/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_11/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_11_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_11/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.672982308599684, 'crowds_classification_s_model_channel_matrix_11_loss': 1.672982308599684, 'baseline_loss': 3.5787242020822134, 'crowds_classification_s_model_channel_matrix_11_acc': 0.005681818181818182, 'baseline_acc': 0.7239057239057239}\n",
      "inputs:  [<tf.Tensor 'sequential_106/dropout_212/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_59/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_12/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_12_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_12/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.609036553989757, 'crowds_classification_s_model_channel_matrix_12_loss': 1.609036553989757, 'baseline_loss': 1.6783116367829396, 'crowds_classification_s_model_channel_matrix_12_acc': 0.020728114478114477, 'baseline_acc': 0.8417508417508418}\n",
      "inputs:  [<tf.Tensor 'sequential_107/dropout_214/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_60/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_13/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_13_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_13/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.617439461075497, 'crowds_classification_s_model_channel_matrix_13_loss': 1.617439461075497, 'baseline_loss': 1.9193267974791806, 'crowds_classification_s_model_channel_matrix_13_acc': 0.007891414141414142, 'baseline_acc': 0.8282828282828283}\n",
      "inputs:  [<tf.Tensor 'sequential_108/dropout_216/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_61/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_14/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_14_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_14/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6103824637955688, 'crowds_classification_s_model_channel_matrix_14_loss': 1.6103824637955688, 'baseline_loss': 1.6516706583588714, 'crowds_classification_s_model_channel_matrix_14_acc': 0.018623737373737372, 'baseline_acc': 0.8383838383838383}\n",
      "inputs:  [<tf.Tensor 'sequential_109/dropout_218/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_62/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_15/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_15_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_15/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.635641412301497, 'crowds_classification_s_model_channel_matrix_15_loss': 1.635641412301497, 'baseline_loss': 1.8217555509271846, 'crowds_classification_s_model_channel_matrix_15_acc': 0.007365319865319866, 'baseline_acc': 0.8148148148148148}\n",
      "inputs:  [<tf.Tensor 'sequential_110/dropout_220/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_63/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_16/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_16_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_16/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6520077259050876, 'crowds_classification_s_model_channel_matrix_16_loss': 1.6520077259050876, 'baseline_loss': 3.182405004979992, 'crowds_classification_s_model_channel_matrix_16_acc': 0.006523569023569023, 'baseline_acc': 0.7668350168350169}\n",
      "inputs:  [<tf.Tensor 'sequential_111/dropout_222/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_64/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_17/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_17_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_17/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6351931962099941, 'crowds_classification_s_model_channel_matrix_17_loss': 1.6351931962099941, 'baseline_loss': 2.2200138086221033, 'crowds_classification_s_model_channel_matrix_17_acc': 0.005892255892255892, 'baseline_acc': 0.8021885521885522}\n",
      "inputs:  [<tf.Tensor 'sequential_112/dropout_224/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_65/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_18/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_18_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_18/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6176294437562577, 'crowds_classification_s_model_channel_matrix_18_loss': 1.6176294437562577, 'baseline_loss': 1.6682592688209883, 'crowds_classification_s_model_channel_matrix_18_acc': 0.011994949494949494, 'baseline_acc': 0.8308080808080808}\n",
      "inputs:  [<tf.Tensor 'sequential_113/dropout_226/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_66/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_19/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_19_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_19/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6250095620299831, 'crowds_classification_s_model_channel_matrix_19_loss': 1.6250095620299831, 'baseline_loss': 1.9261099088071572, 'crowds_classification_s_model_channel_matrix_19_acc': 0.017992424242424244, 'baseline_acc': 0.8122895622895623}\n",
      "inputs:  [<tf.Tensor 'sequential_114/dropout_228/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_67/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_20/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_20_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_20/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6226491863880093, 'crowds_classification_s_model_channel_matrix_20_loss': 1.6226491863880093, 'baseline_loss': 2.048065961737606, 'crowds_classification_s_model_channel_matrix_20_acc': 0.006418350168350169, 'baseline_acc': 0.8148148148148148}\n",
      "inputs:  [<tf.Tensor 'sequential_115/dropout_230/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_68/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_21/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_21_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_21/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.617863872235873, 'crowds_classification_s_model_channel_matrix_21_loss': 1.617863872235873, 'baseline_loss': 1.8210564647058043, 'crowds_classification_s_model_channel_matrix_21_acc': 0.02199074074074074, 'baseline_acc': 0.8265993265993266}\n",
      "inputs:  [<tf.Tensor 'sequential_116/dropout_232/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_69/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_22/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_22_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_22/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6110039728659171, 'crowds_classification_s_model_channel_matrix_22_loss': 1.6110039728659171, 'baseline_loss': 1.674046177843504, 'crowds_classification_s_model_channel_matrix_22_acc': 0.02199074074074074, 'baseline_acc': 0.8358585858585859}\n",
      "inputs:  [<tf.Tensor 'sequential_117/dropout_234/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_70/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_23/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "y_true:  Tensor(\"crowds_classification_s_model_channel_matrix_23_target:0\", shape=(?, ?, ?), dtype=float32)\n",
      "y_pred:  Tensor(\"crowds_classification_s_model_channel_matrix_23/transpose:0\", shape=(?, 8, 59), dtype=float32)\n",
      "Test dataset results: \n",
      "{'loss': 1.6361512985293714, 'crowds_classification_s_model_channel_matrix_23_loss': 1.6361512985293714, 'baseline_loss': 2.0312720119752465, 'crowds_classification_s_model_channel_matrix_23_acc': 0.007154882154882155, 'baseline_acc': 0.8038720538720538}\n",
      "\n",
      "Crowd noise adaptation model with softmax: True, trace: True\n",
      "inputs:  [<tf.Tensor 'sequential_118/dropout_236/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_71/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_24/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.50813104809334, 'crowds_classification_s_model_channel_matrix_24_loss': 6.50813104809334, 'baseline_loss': 1.811613213277174, 'crowds_classification_s_model_channel_matrix_24_acc': 0.007786195286195286, 'baseline_acc': 0.8223905723905723}\n",
      "inputs:  [<tf.Tensor 'sequential_119/dropout_238/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_72/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_25/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.488151293410998, 'crowds_classification_s_model_channel_matrix_25_loss': 6.488151293410998, 'baseline_loss': 1.6208857867854276, 'crowds_classification_s_model_channel_matrix_25_acc': 0.00904882154882155, 'baseline_acc': 0.8484848484848485}\n",
      "inputs:  [<tf.Tensor 'sequential_120/dropout_240/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_73/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_26/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.50871636650779, 'crowds_classification_s_model_channel_matrix_26_loss': 6.50871636650779, 'baseline_loss': 1.9407171697327585, 'crowds_classification_s_model_channel_matrix_26_acc': 0.015151515151515152, 'baseline_acc': 0.8223905723905723}\n",
      "inputs:  [<tf.Tensor 'sequential_121/dropout_242/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_74/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_27/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.50401576520618, 'crowds_classification_s_model_channel_matrix_27_loss': 6.50401576520618, 'baseline_loss': 1.6429042873766135, 'crowds_classification_s_model_channel_matrix_27_acc': 0.0070496632996633, 'baseline_acc': 0.8333333333333334}\n",
      "inputs:  [<tf.Tensor 'sequential_122/dropout_244/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_75/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_28/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.5113669678016945, 'crowds_classification_s_model_channel_matrix_28_loss': 6.5113669678016945, 'baseline_loss': 1.8662211283890888, 'crowds_classification_s_model_channel_matrix_28_acc': 0.017045454545454544, 'baseline_acc': 0.8249158249158249}\n",
      "inputs:  [<tf.Tensor 'sequential_123/dropout_246/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_76/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_29/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.519003139200436, 'crowds_classification_s_model_channel_matrix_29_loss': 6.519003139200436, 'baseline_loss': 2.0454919554970483, 'crowds_classification_s_model_channel_matrix_29_acc': 0.020833333333333332, 'baseline_acc': 0.8148148148148148}\n",
      "inputs:  [<tf.Tensor 'sequential_124/dropout_248/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_77/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_30/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.525254570675218, 'crowds_classification_s_model_channel_matrix_30_loss': 6.525254570675218, 'baseline_loss': 2.1929022981863633, 'crowds_classification_s_model_channel_matrix_30_acc': 0.016308922558922558, 'baseline_acc': 0.8097643097643098}\n",
      "inputs:  [<tf.Tensor 'sequential_125/dropout_250/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_78/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_31/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.567723169872656, 'crowds_classification_s_model_channel_matrix_31_loss': 6.567723169872656, 'baseline_loss': 3.708388747590961, 'crowds_classification_s_model_channel_matrix_31_acc': 0.014625420875420875, 'baseline_acc': 0.7196969696969697}\n",
      "inputs:  [<tf.Tensor 'sequential_126/dropout_252/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_79/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_32/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.523539212416318, 'crowds_classification_s_model_channel_matrix_32_loss': 6.523539212416318, 'baseline_loss': 2.036656724282788, 'crowds_classification_s_model_channel_matrix_32_acc': 0.020622895622895623, 'baseline_acc': 0.8047138047138047}\n",
      "inputs:  [<tf.Tensor 'sequential_127/dropout_254/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_80/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_33/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.504948041254423, 'crowds_classification_s_model_channel_matrix_33_loss': 6.504948041254423, 'baseline_loss': 2.023151767189279, 'crowds_classification_s_model_channel_matrix_33_acc': 0.015467171717171718, 'baseline_acc': 0.8308080808080808}\n",
      "inputs:  [<tf.Tensor 'sequential_128/dropout_256/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_81/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_34/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.507026187498561, 'crowds_classification_s_model_channel_matrix_34_loss': 6.507026187498561, 'baseline_loss': 1.5868753625371101, 'crowds_classification_s_model_channel_matrix_34_acc': 0.006839225589225589, 'baseline_acc': 0.8274410774410774}\n",
      "inputs:  [<tf.Tensor 'sequential_129/dropout_258/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_82/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_35/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.578578133374352, 'crowds_classification_s_model_channel_matrix_35_loss': 6.578578133374352, 'baseline_loss': 3.612811151176992, 'crowds_classification_s_model_channel_matrix_35_acc': 0.00747053872053872, 'baseline_acc': 0.7196969696969697}\n",
      "inputs:  [<tf.Tensor 'sequential_130/dropout_260/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_83/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_36/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.507275252229838, 'crowds_classification_s_model_channel_matrix_36_loss': 6.507275252229838, 'baseline_loss': 1.710978565040681, 'crowds_classification_s_model_channel_matrix_36_acc': 0.01567760942760943, 'baseline_acc': 0.8291245791245792}\n",
      "inputs:  [<tf.Tensor 'sequential_131/dropout_262/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_84/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_37/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.517292481881601, 'crowds_classification_s_model_channel_matrix_37_loss': 6.517292481881601, 'baseline_loss': 1.9053707596428868, 'crowds_classification_s_model_channel_matrix_37_acc': 0.014625420875420875, 'baseline_acc': 0.8173400673400674}\n",
      "inputs:  [<tf.Tensor 'sequential_132/dropout_264/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_85/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_38/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.505597575345023, 'crowds_classification_s_model_channel_matrix_38_loss': 6.505597575345023, 'baseline_loss': 1.965347033903404, 'crowds_classification_s_model_channel_matrix_38_acc': 0.0140993265993266, 'baseline_acc': 0.8316498316498316}\n",
      "inputs:  [<tf.Tensor 'sequential_133/dropout_266/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_86/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_39/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.509722947271585, 'crowds_classification_s_model_channel_matrix_39_loss': 6.509722947271585, 'baseline_loss': 2.0871275993007603, 'crowds_classification_s_model_channel_matrix_39_acc': 0.017676767676767676, 'baseline_acc': 0.8265993265993266}\n",
      "inputs:  [<tf.Tensor 'sequential_134/dropout_268/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_87/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_40/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.511481636702412, 'crowds_classification_s_model_channel_matrix_40_loss': 6.511481636702412, 'baseline_loss': 1.821744376160079, 'crowds_classification_s_model_channel_matrix_40_acc': 0.017466329966329967, 'baseline_acc': 0.8308080808080808}\n",
      "inputs:  [<tf.Tensor 'sequential_135/dropout_270/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_88/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_41/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.524860988963734, 'crowds_classification_s_model_channel_matrix_41_loss': 6.524860988963734, 'baseline_loss': 2.23039700192484, 'crowds_classification_s_model_channel_matrix_41_acc': 0.017676767676767676, 'baseline_acc': 0.8005050505050505}\n",
      "inputs:  [<tf.Tensor 'sequential_136/dropout_272/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_89/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_42/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.512845806802563, 'crowds_classification_s_model_channel_matrix_42_loss': 6.512845806802563, 'baseline_loss': 1.6129737953947048, 'crowds_classification_s_model_channel_matrix_42_acc': 0.014625420875420875, 'baseline_acc': 0.8265993265993266}\n",
      "inputs:  [<tf.Tensor 'sequential_137/dropout_274/cond/Merge:0' shape=(?, 64) dtype=float32>, <tf.Tensor 'baseline_90/Softmax:0' shape=(?, 8) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_43/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>]\n",
      "(8,)\n",
      "Test dataset results: \n",
      "{'loss': 6.521956912596218, 'crowds_classification_s_model_channel_matrix_43_loss': 6.521956912596218, 'baseline_loss': 2.036246058339824, 'crowds_classification_s_model_channel_matrix_43_acc': 0.017045454545454544, 'baseline_acc': 0.8072390572390572}\n"
     ]
    }
   ],
   "source": [
    "NUM_RUNS = 20\n",
    "N_CLASSES = 8\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 35\n",
    "W = 0\n",
    "\n",
    "DATA_PATH = \"/home/yajingyang/Downloads/LabelMe/prepared/\"\n",
    "x, y_gt, y_annot = get_data(DATA_PATH, N_CLASSES)\n",
    "\n",
    "N_ANNOT = y_annot['train'].shape[2]\n",
    "\n",
    "# print('baseline model with majority vote labels:')\n",
    "# for i in range(NUM_RUNS):\n",
    "#     base_acc_df = pd.DataFrame()\n",
    "#     base_loss_df = pd.DataFrame()\n",
    "#     base_history = majority_vote(x, y_gt, y_annot, N_CLASSES)\n",
    "#     base_acc_df.loc[:, i] = base_history.history['acc']\n",
    "#     base_loss_df.loc[:, i] = base_history.history['loss']\n",
    "\n",
    "#     base_acc_df.to_csv('base_accuracy.csv')\n",
    "#     base_loss_df.to_csv('base_loss.csv')\n",
    "# #     print_history(base_acc_df, 'accuracy')\n",
    "# #     print_history(base_loss_df, 'loss')\n",
    "\n",
    "# print('baseline model with clean labels')\n",
    "# for i in range(NUM_RUNS):\n",
    "#     clean_base_acc_df = pd.DataFrame()\n",
    "#     clean_base_loss_df = pd.DataFrame()\n",
    "#     clean_history = baseline_gt(x, y_gt, N_CLASSES)\n",
    "#     clean_base_acc_df.loc[:, i] = clean_history.history['acc']\n",
    "#     clean_base_loss_df.loc[:, i] = clean_history.history['loss']\n",
    "\n",
    "#     clean_base_acc_df.to_csv('clean_accuracy.csv')\n",
    "#     clean_base_loss_df.to_csv('clean_loss.csv')\n",
    "# #     print_history(clean_acc_df, 'accuracy')\n",
    "# #     print_history(clean_loss_df, 'loss')\n",
    "\n",
    "\n",
    "\n",
    "for softmax in [False, True]:\n",
    "    for trace in [False, True]:\n",
    "        print('\\nCrowd noise adaptation model with softmax: %s, trace: %s' % (softmax, trace))\n",
    "        prefix = ''\n",
    "        if softmax: \n",
    "            prefix = 'softmax_'\n",
    "        if trace:\n",
    "            prefix = prefix + 'trace_'\n",
    "        loss_csv = prefix + 'loss.csv'\n",
    "        acc_csv = prefix + 'acc.csv'\n",
    "        trace_csv = prefix + 'trace.csv'\n",
    "        acc_df = pd.DataFrame()\n",
    "        loss_df = pd.DataFrame()\n",
    "        trace_df = pd.DataFrame()\n",
    "        \n",
    "        for i in range(NUM_RUNS):\n",
    "            history, trace_arr = crowd_model(x, y_gt, y_annot, N_CLASSES, softmax, trace)\n",
    "            acc_df.loc[:, i] = history.history['baseline_acc']\n",
    "            loss_df.loc[:, i] = history.history['baseline_loss']\n",
    "            trace_df.loc[:, i] = trace_arr\n",
    "\n",
    "        acc_df.to_csv(acc_csv)\n",
    "        loss_df.to_csv(loss_csv)\n",
    "        trace_df.to_csv(trace_csv)\n",
    "\n",
    "#     print_history(trace_crowd_acc_df, 'accuracy')\n",
    "#     print_history(trace_crowd_loss_df, 'loss')\n",
    "# acc_df.loc[:, str(b)] = history.history['baseline_acc']\n",
    "# loss_df.loc[:, str(b)] = history.history['baseline_loss']\n",
    "\n",
    "# acc_df.to_csv('accuracy.csv')\n",
    "# loss_df.to_csv('loss.csv')\n",
    "# print_history(acc_df, 'accuracy')\n",
    "# print_history(loss_df, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Bird Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cactus Wren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(3069, 7, 7, 512)\n",
      "(3069,)\n",
      "(3069,)\n",
      "\n",
      "Loading AMT data...\n",
      "(3069, 31)\n",
      "N_CLASSES: 2\n",
      "N_ANNOT: 31\n",
      "\n",
      "Loading test data...\n",
      "(176, 7, 7, 512)\n",
      "(176,)\n",
      "\n",
      "Loading validation data...\n",
      "(363, 7, 7, 512)\n",
      "(363,)\n",
      "\n",
      "baseline model with clean labels:\n",
      "Test dataset results: \n",
      "{'loss': 4.580449364402077, 'acc': 0.6420454545454546}\n",
      "Test dataset results: \n",
      "{'loss': 2.014761946418069, 'acc': 0.875}\n",
      "Test dataset results: \n",
      "{'loss': 1.6465330990878018, 'acc': 0.7386363636363636}\n",
      "Test dataset results: \n",
      "{'loss': 1.007381016557867, 'acc': 0.9375}\n",
      "\n",
      "baseline model with majority vote labels:\n",
      "Test dataset results: \n",
      "{'loss': 2.49463267107223, 'acc': 0.7840909090909091}\n",
      "Test dataset results: \n",
      "{'loss': 2.747402613813227, 'acc': 0.8295454545454546}\n",
      "Test dataset results: \n",
      "{'loss': 9.89710773121227, 'acc': 0.24431818181818182}\n",
      "Test dataset results: \n",
      "{'loss': 1.8316018256274136, 'acc': 0.8863636363636364}\n",
      "\n",
      "crowd noise adaptation model:\n",
      "inputs:  [<tf.Tensor 'sequential_54/dropout_58/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_16/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_17/CrowdLayer:0' shape=(2, 2, 31) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.965367848222906, 'crowds_classification_s_model_channel_matrix_17_loss': 1.965367848222906, 'baseline_loss': 7.394810849970037, 'crowds_classification_s_model_channel_matrix_17_acc': 0.08522727272727272, 'baseline_acc': 0.3465909090909091}\n",
      "[-1.2145348 -1.222816  -1.2283239 -1.2283609 -1.2212453 -1.2242062\n",
      " -1.2284982 -1.2317678 -1.218075  -1.2257532 -1.2219071 -1.222049\n",
      " -1.2245255 -1.2205535 -1.2268302 -1.2289101 -1.2258186 -1.2163831\n",
      " -1.2224633 -1.218777  -1.2224998 -1.2273726 -1.2308598 -1.2217655\n",
      " -1.224704  -1.2184628 -1.2277637 -1.2150924 -1.2168875 -1.2214345\n",
      " -1.2224519]\n",
      "[-0.05335602  0.37418503 -0.02978235 -0.45479172  0.19985743  0.287719\n",
      " -1.2153287  -0.22152734 -0.58365655 -0.14410618 -0.4113449  -0.02904806\n",
      " -0.33202973 -0.5428674  -0.3458145  -0.01546493 -0.15257566 -0.37932542\n",
      " -1.2395889  -0.4009359  -1.2886758  -0.03542978  0.21425138 -0.09808487\n",
      " -0.8290505  -0.81355363 -1.6498114  -1.6273695  -1.5924728  -0.00810894\n",
      "  0.2408826 ]\n",
      "Test dataset results: \n",
      "{'loss': 1.866253744472157, 'crowds_classification_s_model_channel_matrix_17_loss': 1.866253744472157, 'baseline_loss': 4.304264166138389, 'crowds_classification_s_model_channel_matrix_17_acc': 0.0, 'baseline_acc': 0.7329545454545454}\n",
      "inputs:  [<tf.Tensor 'sequential_55/dropout_59/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_17/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_18/CrowdLayer:0' shape=(2, 2, 31) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.9649707729166204, 'crowds_classification_s_model_channel_matrix_18_loss': 1.9649707729166204, 'baseline_loss': 7.276861971074885, 'crowds_classification_s_model_channel_matrix_18_acc': 0.0, 'baseline_acc': 0.4375}\n",
      "[-1.2250197 -1.224402  -1.2247782 -1.2259915 -1.2222698 -1.2228286\n",
      " -1.2232888 -1.21521   -1.2240584 -1.2160335 -1.2231953 -1.2213252\n",
      " -1.2241437 -1.2271719 -1.2213378 -1.2242043 -1.2230151 -1.2206354\n",
      " -1.2266321 -1.2206974 -1.2221569 -1.2315139 -1.2174493 -1.214993\n",
      " -1.2183373 -1.216233  -1.219172  -1.2206578 -1.2201128 -1.217938\n",
      " -1.2224355]\n",
      "[-0.07025611  0.53250134  0.04522908 -0.24777141  0.24132088  0.21664801\n",
      " -1.2722995  -0.03572831 -0.48678023  0.00391683 -0.4608474   0.14354768\n",
      " -0.25508755 -0.44029063 -0.19981241  0.08891973 -0.22680983 -0.48627758\n",
      " -1.2317109  -0.37202564 -1.2138941   0.27905273  0.26002     0.18675552\n",
      " -0.71749127 -0.7197671  -1.7170966  -1.7213128  -1.7404995  -0.00685543\n",
      "  0.35208002]\n",
      "Test dataset results: \n",
      "{'loss': 1.8877869085832075, 'crowds_classification_s_model_channel_matrix_18_loss': 1.8877869085832075, 'baseline_loss': 4.3963140791112725, 'crowds_classification_s_model_channel_matrix_18_acc': 0.0, 'baseline_acc': 0.7272727272727273}\n"
     ]
    }
   ],
   "source": [
    "NUM_RUNS = 2\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 35\n",
    "W = 0\n",
    "\n",
    "DATA_PATH = '/home/yajingyang/PycharmProjects/online_crowdsourcing/data/classification/cub_40/images/Cactus Wren/'\n",
    "x, y_gt, y_annot = get_data(DATA_PATH, N_CLASSES)\n",
    "\n",
    "N_ANNOT = y_annot['train'].shape[2]\n",
    "\n",
    "print('\\nbaseline model with clean labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    baseline_gt(x, y_gt, N_CLASSES)\n",
    "    \n",
    "print('\\nbaseline model with majority vote labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    majority_vote(x, y_gt, y_annot, N_CLASSES)\n",
    "    \n",
    "print('\\ncrowd noise adaptation model:')\n",
    "for i in range(NUM_RUNS):\n",
    "    crowd_model(x, y_gt, y_annot, N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(3510, 7, 7, 512)\n",
      "(3510,)\n",
      "(3510,)\n",
      "\n",
      "Loading AMT data...\n",
      "(3510, 40)\n",
      "N_CLASSES: 2\n",
      "N_ANNOT: 40\n",
      "\n",
      "Loading test data...\n",
      "(210, 7, 7, 512)\n",
      "(210,)\n",
      "\n",
      "Loading validation data...\n",
      "(405, 7, 7, 512)\n",
      "(405,)\n",
      "\n",
      "baseline model with majority vote labels:\n",
      "Test dataset results: \n",
      "{'loss': 3.363896878560384, 'acc': 0.6476190487543741}\n",
      "Test dataset results: \n",
      "{'loss': 3.453891637211754, 'acc': 0.7857142857142857}\n",
      "Test dataset results: \n",
      "{'loss': 10.050633058093844, 'acc': 0.2857142858562015}\n",
      "Test dataset results: \n",
      "{'loss': 3.453877686318897, 'acc': 0.7857142857142857}\n",
      "\n",
      "baseline model with clean labels:\n",
      "Test dataset results: \n",
      "{'loss': 7.196937047867548, 'acc': 0.4190476207506089}\n",
      "Test dataset results: \n",
      "{'loss': 3.453877686318897, 'acc': 0.7857142857142857}\n",
      "Test dataset results: \n",
      "{'loss': 5.360020560310001, 'acc': 0.5095238098076411}\n",
      "Test dataset results: \n",
      "{'loss': 3.453877686318897, 'acc': 0.7857142857142857}\n",
      "\n",
      "crowd noise adaptation model:\n",
      "inputs:  [<tf.Tensor 'sequential_36/dropout_36/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_10/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_11/CrowdLayer:0' shape=(2, 2, 40) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.954318726630438, 'crowds_classification_s_model_channel_matrix_11_loss': 1.954318726630438, 'baseline_loss': 4.963432365372068, 'crowds_classification_s_model_channel_matrix_11_acc': 0.06904761933145069, 'baseline_acc': 0.5190476173446292}\n",
      "[-1.214625  -1.2225301 -1.2315772 -1.2202654 -1.2156637 -1.219775\n",
      " -1.2205465 -1.2202355 -1.2246528 -1.2240222 -1.2230691 -1.2218487\n",
      " -1.2168307 -1.2156943 -1.2256112 -1.2219603 -1.2200146 -1.2230723\n",
      " -1.2316959 -1.2192756 -1.225567  -1.2213427 -1.2213001 -1.224585\n",
      " -1.2218451 -1.2185788 -1.2295411 -1.2284455 -1.2232418 -1.2289993\n",
      " -1.2284415 -1.2203555 -1.2188916 -1.2198966 -1.2263379 -1.2189612\n",
      " -1.2228476 -1.2209213 -1.2189511 -1.2249522]\n",
      "[-0.11793998 -0.05818248 -0.13086095 -0.2770066  -0.2615344  -0.05057818\n",
      " -0.8260736  -1.7610115  -1.282572   -0.16903532 -0.08748335 -2.1466975\n",
      " -0.10428065 -0.06714797 -0.06941676 -0.5833692  -0.5632809  -0.57106054\n",
      " -1.4741534  -0.3905257  -0.05126268 -0.14119849 -0.19573602 -0.57210696\n",
      " -1.90217    -0.5743197  -2.4272501  -2.3583794  -0.08687335 -0.576204\n",
      " -1.9232346  -0.54916877 -0.58648646 -0.71561116 -2.2863088  -1.7608438\n",
      " -0.43456045 -1.8832152  -1.8755567  -1.8991568 ]\n",
      "Test dataset results: \n",
      "{'loss': 1.9380079757599604, 'crowds_classification_s_model_channel_matrix_11_loss': 1.9380079757599604, 'baseline_loss': 3.453877686318897, 'crowds_classification_s_model_channel_matrix_11_acc': 0.0, 'baseline_acc': 0.7857142857142857}\n",
      "inputs:  [<tf.Tensor 'sequential_37/dropout_37/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_11/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_12/CrowdLayer:0' shape=(2, 2, 40) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.968616415205456, 'crowds_classification_s_model_channel_matrix_12_loss': 1.968616415205456, 'baseline_loss': 8.890265473865327, 'crowds_classification_s_model_channel_matrix_12_acc': 0.0, 'baseline_acc': 0.3666666667376246}\n",
      "[-1.2223322 -1.2280217 -1.2230384 -1.2199016 -1.2236457 -1.2289549\n",
      " -1.2240506 -1.229531  -1.2239687 -1.2258353 -1.2227023 -1.2204988\n",
      " -1.2272933 -1.2167273 -1.2229995 -1.223974  -1.2276158 -1.2272159\n",
      " -1.2142353 -1.2160599 -1.2276628 -1.2206247 -1.2184012 -1.2223468\n",
      " -1.2158633 -1.2275271 -1.2171713 -1.2228966 -1.2204975 -1.2193968\n",
      " -1.2190998 -1.2243402 -1.2179408 -1.2270055 -1.2227778 -1.2170029\n",
      " -1.2180742 -1.2272317 -1.2259493 -1.2253311]\n",
      "[-0.2146227   0.2649197  -0.24356124 -0.3544624  -0.35027838 -0.17893767\n",
      " -0.24130052 -1.7681172  -1.2195606   0.16856796 -0.14874226 -2.0809147\n",
      " -0.19239861 -0.11651659 -0.12091118 -0.5953253  -0.60212994 -0.5649527\n",
      " -1.4135033  -0.34934908 -0.45663053 -0.1899243  -0.6809007  -0.5833593\n",
      " -1.8529342  -0.6219734  -2.3342924  -2.2669568  -0.20060378 -0.5620404\n",
      " -1.8955861  -0.5580819  -0.58448946 -0.20409276 -1.7529298  -1.0968785\n",
      "  0.13220333 -1.8241385  -1.8805497  -1.901188  ]\n",
      "Test dataset results: \n",
      "{'loss': 1.932643416949681, 'crowds_classification_s_model_channel_matrix_12_loss': 1.932643416949681, 'baseline_loss': 3.453877686318897, 'crowds_classification_s_model_channel_matrix_12_acc': 0.0023809523986918586, 'baseline_acc': 0.7857142857142857}\n"
     ]
    }
   ],
   "source": [
    "NUM_RUNS = 2\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 35\n",
    "W = 0\n",
    "\n",
    "DATA_PATH = '/home/yajingyang/PycharmProjects/online_crowdsourcing/data/classification/cub_40/images/Cape May Warbler/'\n",
    "x, y_gt, y_annot = get_data(DATA_PATH, N_CLASSES)\n",
    "\n",
    "N_ANNOT = y_annot['train'].shape[2]\n",
    "    \n",
    "print('\\nbaseline model with majority vote labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    majority_vote(x, y_gt, y_annot, N_CLASSES)\n",
    "    \n",
    "print('\\nbaseline model with clean labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    baseline_gt(x, y_gt, N_CLASSES)\n",
    "\n",
    "    \n",
    "print('\\ncrowd noise adaptation model:')\n",
    "for i in range(NUM_RUNS):\n",
    "    crowd_model(x, y_gt, y_annot, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(4605, 7, 7, 512)\n",
      "(4605,)\n",
      "(4605,)\n",
      "\n",
      "Loading AMT data...\n",
      "(4605, 26)\n",
      "N_CLASSES: 2\n",
      "N_ANNOT: 26\n",
      "\n",
      "Loading test data...\n",
      "(270, 7, 7, 512)\n",
      "(270,)\n",
      "\n",
      "Loading validation data...\n",
      "(540, 7, 7, 512)\n",
      "(540,)\n",
      "\n",
      "baseline model with majority vote labels:\n",
      "Test dataset results: \n",
      "{'loss': 5.301747682359483, 'acc': 0.5111111114422481}\n",
      "Test dataset results: \n",
      "{'loss': 2.686349210915742, 'acc': 0.8333333333333334}\n",
      "Test dataset results: \n",
      "{'loss': 8.372794212456103, 'acc': 0.3370370357124894}\n",
      "Test dataset results: \n",
      "{'loss': 2.686349210915742, 'acc': 0.8333333333333334}\n",
      "\n",
      "baseline model with clean labels:\n",
      "Test dataset results: \n",
      "{'loss': 6.542580353772199, 'acc': 0.4629629620799312}\n",
      "Test dataset results: \n",
      "{'loss': 2.686349210915742, 'acc': 0.8333333333333334}\n",
      "Test dataset results: \n",
      "{'loss': 6.45135940975613, 'acc': 0.4555555558866925}\n",
      "Test dataset results: \n",
      "{'loss': 2.746045853473522, 'acc': 0.8296296296296296}\n",
      "\n",
      "crowd noise adaptation model:\n",
      "inputs:  [<tf.Tensor 'sequential_42/dropout_42/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_12/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_13/CrowdLayer:0' shape=(2, 2, 26) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.98194877659833, 'crowds_classification_s_model_channel_matrix_13_loss': 1.98194877659833, 'baseline_loss': 12.234007828323929, 'crowds_classification_s_model_channel_matrix_13_acc': 0.007407407407407408, 'baseline_acc': 0.18518518518518517}\n",
      "[-1.2201753 -1.2268286 -1.214236  -1.2193261 -1.2176983 -1.2275063\n",
      " -1.225966  -1.2285258 -1.2298713 -1.2230749 -1.2142867 -1.2132062\n",
      " -1.2232786 -1.2168393 -1.2270377 -1.2207963 -1.2258315 -1.2266085\n",
      " -1.2213564 -1.2252138 -1.2309152 -1.2253373 -1.2243654 -1.2218494\n",
      " -1.2136307 -1.221777 ]\n",
      "[-0.52776045 -1.3540683  -0.4177078  -0.11545622 -0.54134107  0.33389422\n",
      " -0.03999372 -0.07815816  0.47176585 -1.0085231  -0.28538436 -1.8284719\n",
      "  0.31436607  0.3176101  -0.447317   -0.01539969 -1.7737968  -1.0395633\n",
      " -0.04230124 -0.09205562 -1.0095183  -1.3070513  -0.13641775 -0.01144341\n",
      " -0.15482259 -0.04833603]\n",
      "Test dataset results: \n",
      "{'loss': 1.8779728456779763, 'crowds_classification_s_model_channel_matrix_13_loss': 1.8779728456779763, 'baseline_loss': 2.686349210915742, 'crowds_classification_s_model_channel_matrix_13_acc': 0.003703703703703704, 'baseline_acc': 0.8333333333333334}\n",
      "inputs:  [<tf.Tensor 'sequential_43/dropout_43/cond/Merge:0' shape=(?, 128) dtype=float32>, <tf.Tensor 'baseline_13/Softmax:0' shape=(?, 2) dtype=float32>]\n",
      "weights:  [<tf.Variable 'crowds_classification_s_model_channel_matrix_14/CrowdLayer:0' shape=(2, 2, 26) dtype=float32_ref>]\n",
      "(2,)\n",
      "Test dataset results: \n",
      "{'loss': 1.964492815512198, 'crowds_classification_s_model_channel_matrix_14_loss': 1.964492815512198, 'baseline_loss': 6.003401629130045, 'crowds_classification_s_model_channel_matrix_14_acc': 0.10370370381408267, 'baseline_acc': 0.4481481482585271}\n",
      "[-1.2240474 -1.220388  -1.2233236 -1.2212448 -1.2210826 -1.2254007\n",
      " -1.2240303 -1.2255814 -1.2255785 -1.2240349 -1.2194164 -1.2251365\n",
      " -1.2174225 -1.2228318 -1.2236248 -1.2192252 -1.216672  -1.2189465\n",
      " -1.2299571 -1.2166123 -1.2205992 -1.2148399 -1.2222056 -1.2236384\n",
      " -1.2202098 -1.2222602]\n",
      "[-1.1409558  -1.8622302   0.11297405 -0.03880447 -0.24117842 -0.33372113\n",
      " -0.81494397 -0.6601999  -0.18892744 -1.7279867  -0.76113975 -2.3207715\n",
      "  0.10346997 -0.0210706   0.13587284 -0.40078482 -2.2298121  -1.5567228\n",
      "  0.06068504  0.13652474 -1.0685005  -1.4518511   0.16919917 -0.19692948\n",
      "  0.17287344  0.08832288]\n",
      "Test dataset results: \n",
      "{'loss': 1.8893143830475985, 'crowds_classification_s_model_channel_matrix_14_loss': 1.8893143830475985, 'baseline_loss': 2.686349210915742, 'crowds_classification_s_model_channel_matrix_14_acc': 0.001851851851851852, 'baseline_acc': 0.8333333333333334}\n"
     ]
    }
   ],
   "source": [
    "NUM_RUNS = 2\n",
    "N_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 35\n",
    "W = 0\n",
    "\n",
    "DATA_PATH = '/home/yajingyang/PycharmProjects/online_crowdsourcing/data/classification/cub_40/images/Evening Grosbeak/'\n",
    "x, y_gt, y_annot = get_data(DATA_PATH, N_CLASSES)\n",
    "\n",
    "N_ANNOT = y_annot['train'].shape[2]\n",
    "    \n",
    "print('\\nbaseline model with majority vote labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    majority_vote(x, y_gt, y_annot, N_CLASSES)\n",
    "    \n",
    "print('\\nbaseline model with clean labels:')\n",
    "for i in range(NUM_RUNS):\n",
    "    baseline_gt(x, y_gt, N_CLASSES)\n",
    "\n",
    "    \n",
    "print('\\ncrowd noise adaptation model:')\n",
    "for i in range(NUM_RUNS):\n",
    "    crowd_model(x, y_gt, y_annot, N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
