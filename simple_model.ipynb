{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import pyplot as plt \n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import Input\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "# packages for learning from crowds\n",
    "from crowd_layer.crowd_layers import CrowdsClassification, MaskedMultiCrossEntropy\n",
    "from crowd_layer.crowd_aggregators import CrowdsCategoricalAggregator\n",
    "\n",
    "# prevent tensorflow from allocating the entire GPU memory at once\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_RUNS = 30\n",
    "DATA_PATH = \"/Users/yangyajing/Documents/noisy_dataset/LabelMe/prepared/\"\n",
    "N_CLASSES = 8\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    f = open(filename, 'rb')\n",
    "    data = np.load(f)\n",
    "    f.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading train data...\n",
      "(10000, 4, 4, 512)\n",
      "(10000,)\n",
      "(10000,)\n",
      "(10000,)\n",
      "\n",
      "Loading AMT data...\n",
      "(10000, 59)\n",
      "\n",
      "N_CLASSES: 8\n",
      "N_ANNOT: 59\n",
      "\n",
      "Loading test data...\n",
      "(1188, 4, 4, 512)\n",
      "(1188,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading train data...\")\n",
    "\n",
    "# images processed by VGG16\n",
    "data_train_vgg16 = load_data(DATA_PATH+\"data_train_vgg16.npy\")\n",
    "print(data_train_vgg16.shape)\n",
    "\n",
    "# ground truth labels\n",
    "labels_train = load_data(DATA_PATH+\"labels_train.npy\")\n",
    "print(labels_train.shape)\n",
    "\n",
    "# labels obtained from majority voting\n",
    "labels_train_mv = load_data(DATA_PATH+\"labels_train_mv.npy\")\n",
    "print(labels_train_mv.shape)\n",
    "\n",
    "# labels obtained by using the approach by Dawid and Skene\n",
    "labels_train_ds = load_data(DATA_PATH+\"labels_train_DS.npy\")\n",
    "print(labels_train_ds.shape)\n",
    "\n",
    "# data from Amazon Mechanical Turk\n",
    "print(\"\\nLoading AMT data...\")\n",
    "answers = load_data(DATA_PATH+\"answers.npy\")\n",
    "print(answers.shape)\n",
    "N_ANNOT = answers.shape[1]\n",
    "print(\"\\nN_CLASSES:\", N_CLASSES)\n",
    "print(\"N_ANNOT:\", N_ANNOT)\n",
    "\n",
    "# load test data\n",
    "print(\"\\nLoading test data...\")\n",
    "\n",
    "# images processed by VGG16\n",
    "data_test_vgg16 = load_data(DATA_PATH+\"data_test_vgg16.npy\")\n",
    "print(data_test_vgg16.shape)\n",
    "\n",
    "# test labels\n",
    "labels_test = load_data(DATA_PATH+\"labels_test.npy\")\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(target, n_classes):\n",
    "    targets = np.array([target]).reshape(-1)\n",
    "    one_hot_targets = np.eye(n_classes)[targets]\n",
    "    return one_hot_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to one-hot encoding...\n",
      "(10000, 8)\n",
      "(10000, 8)\n",
      "(10000, 8)\n",
      "(1188, 8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 8, 59)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nConverting to one-hot encoding...\")\n",
    "labels_train_bin = one_hot(labels_train, N_CLASSES)\n",
    "print(labels_train_bin.shape)\n",
    "labels_train_mv_bin = one_hot(labels_train_mv, N_CLASSES)\n",
    "print(labels_train_mv_bin.shape)\n",
    "labels_train_ds_bin = one_hot(labels_train_ds, N_CLASSES)\n",
    "print(labels_train_ds_bin.shape)\n",
    "labels_test_bin = one_hot(labels_test, N_CLASSES)\n",
    "print(labels_test_bin.shape)\n",
    "\n",
    "answers_bin_missings = []\n",
    "for i in range(len(answers)):\n",
    "    row = []\n",
    "    for r in range(N_ANNOT):\n",
    "        if answers[i,r] == -1:\n",
    "            row.append(-1 * np.ones(N_CLASSES))\n",
    "        else:\n",
    "            row.append(one_hot(answers[i,r], N_CLASSES)[0,:])\n",
    "    answers_bin_missings.append(row)\n",
    "answers_bin_missings = np.array(answers_bin_missings).swapaxes(1,2)\n",
    "answers_bin_missings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1188, 8, 59)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test_bin_missings = np.zeros((len(labels_test), N_CLASSES))\n",
    "answers_test_bin_missings[np.arange(len(labels_test)), labels_test] = 1\n",
    "answers_test_bin_missings = np.repeat(answers_test_bin_missings.reshape([len(labels_test),N_CLASSES,1]), N_ANNOT, axis=2)\n",
    "answers_test_bin_missings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval(model,y_test):\n",
    "    return dict(zip(model.metrics_names,model.evaluate(data_test_vgg16,y_test, verbose=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"baseline_1/Softmax:0\", shape=(?, 8), dtype=float32)\n",
      "<tf.Variable 'crowds_classification_2/CrowdLayer:0' shape=(8, 8, 59) dtype=float32_ref>\n",
      "Tensor(\"crowds_classification_2/Reshape_2:0\", shape=(?, 8, 59), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "hidden_layers = Sequential()\n",
    "hidden_layers.add(Flatten(input_shape=data_train_vgg16.shape[1:]))\n",
    "hidden_layers.add(Dense(128, activation='relu'))\n",
    "hidden_layers.add(Dropout(0.5))\n",
    "\n",
    "train_inputs = Input(shape=(data_train_vgg16.shape[1:]))\n",
    "last_hidden = hidden_layers(train_inputs)\n",
    "baseline_output = Dense(N_CLASSES, activation='softmax', name='baseline')(last_hidden)\n",
    "\n",
    "# add crowds layer on top of the base model\n",
    "channeled_output = CrowdsClassification(N_CLASSES, N_ANNOT, conn_type=\"MW\")(baseline_output)\n",
    "print(channeled_output)\n",
    "simple_model = Model(inputs=train_inputs, outputs=[channeled_output, baseline_output])\n",
    "\n",
    "# instantiate specialized masked loss to handle missing answers\n",
    "loss = MaskedMultiCrossEntropy().loss\n",
    "\n",
    "# compile model with masked loss and train\n",
    "simple_model.compile(optimizer='adam', \n",
    "                     loss=[loss,'categorical_crossentropy'], \n",
    "                     loss_weights=[1,0],\n",
    "                     metrics=['accuracy']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0712 - crowds_classification_2_loss: 0.0712 - baseline_loss: 2.0077 - crowds_classification_2_acc: 0.0240 - baseline_acc: 0.6029     \n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0621 - crowds_classification_2_loss: 0.0621 - baseline_loss: 1.3414 - crowds_classification_2_acc: 0.0214 - baseline_acc: 0.7543     \n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0570 - crowds_classification_2_loss: 0.0570 - baseline_loss: 1.2790 - crowds_classification_2_acc: 0.0189 - baseline_acc: 0.7910     \n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0529 - crowds_classification_2_loss: 0.0529 - baseline_loss: 1.2403 - crowds_classification_2_acc: 0.0178 - baseline_acc: 0.8072     \n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0490 - crowds_classification_2_loss: 0.0490 - baseline_loss: 1.2485 - crowds_classification_2_acc: 0.0188 - baseline_acc: 0.8234     \n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0457 - crowds_classification_2_loss: 0.0457 - baseline_loss: 1.1868 - crowds_classification_2_acc: 0.0202 - baseline_acc: 0.8368     \n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0430 - crowds_classification_2_loss: 0.0430 - baseline_loss: 1.2022 - crowds_classification_2_acc: 0.0192 - baseline_acc: 0.8405     \n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0403 - crowds_classification_2_loss: 0.0403 - baseline_loss: 1.1996 - crowds_classification_2_acc: 0.0203 - baseline_acc: 0.8503     - ETA: 0s - loss: 0.0406 - crowds_classification_2_loss: 0.0406 - baseline_loss: 1.1740 - crowds_classification_2_acc: 0.0200 - bas\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0378 - crowds_classification_2_loss: 0.0378 - baseline_loss: 1.1698 - crowds_classification_2_acc: 0.0204 - baseline_acc: 0.8591     \n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0360 - crowds_classification_2_loss: 0.0360 - baseline_loss: 1.2000 - crowds_classification_2_acc: 0.0201 - baseline_acc: 0.8574     \n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0342 - crowds_classification_2_loss: 0.0342 - baseline_loss: 1.1767 - crowds_classification_2_acc: 0.0204 - baseline_acc: 0.8610     \n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0329 - crowds_classification_2_loss: 0.0329 - baseline_loss: 1.1891 - crowds_classification_2_acc: 0.0201 - baseline_acc: 0.8594     \n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0312 - crowds_classification_2_loss: 0.0312 - baseline_loss: 1.1507 - crowds_classification_2_acc: 0.0205 - baseline_acc: 0.8640     \n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0303 - crowds_classification_2_loss: 0.0303 - baseline_loss: 1.1506 - crowds_classification_2_acc: 0.0198 - baseline_acc: 0.8626     \n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0287 - crowds_classification_2_loss: 0.0287 - baseline_loss: 1.1578 - crowds_classification_2_acc: 0.0191 - baseline_acc: 0.8684     \n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0283 - crowds_classification_2_loss: 0.0283 - baseline_loss: 1.1057 - crowds_classification_2_acc: 0.0185 - baseline_acc: 0.8605     \n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0272 - crowds_classification_2_loss: 0.0272 - baseline_loss: 1.1401 - crowds_classification_2_acc: 0.0189 - baseline_acc: 0.8669     \n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0261 - crowds_classification_2_loss: 0.0261 - baseline_loss: 1.0753 - crowds_classification_2_acc: 0.0188 - baseline_acc: 0.8697     \n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0255 - crowds_classification_2_loss: 0.0255 - baseline_loss: 1.1388 - crowds_classification_2_acc: 0.0184 - baseline_acc: 0.8641     \n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0245 - crowds_classification_2_loss: 0.0245 - baseline_loss: 1.1127 - crowds_classification_2_acc: 0.0183 - baseline_acc: 0.8703     \n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0239 - crowds_classification_2_loss: 0.0239 - baseline_loss: 1.1189 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8716     \n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0234 - crowds_classification_2_loss: 0.0234 - baseline_loss: 1.0848 - crowds_classification_2_acc: 0.0184 - baseline_acc: 0.8693     \n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0223 - crowds_classification_2_loss: 0.0223 - baseline_loss: 1.0680 - crowds_classification_2_acc: 0.0182 - baseline_acc: 0.8752     \n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0224 - crowds_classification_2_loss: 0.0224 - baseline_loss: 1.0704 - crowds_classification_2_acc: 0.0182 - baseline_acc: 0.8693     \n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0217 - crowds_classification_2_loss: 0.0217 - baseline_loss: 1.0762 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8702     \n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0210 - crowds_classification_2_loss: 0.0210 - baseline_loss: 1.0782 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8759     \n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0207 - crowds_classification_2_loss: 0.0207 - baseline_loss: 1.0619 - crowds_classification_2_acc: 0.0187 - baseline_acc: 0.8731     \n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0210 - crowds_classification_2_loss: 0.0210 - baseline_loss: 1.0329 - crowds_classification_2_acc: 0.0177 - baseline_acc: 0.8687     \n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0200 - crowds_classification_2_loss: 0.0200 - baseline_loss: 1.0343 - crowds_classification_2_acc: 0.0174 - baseline_acc: 0.8722     \n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0194 - crowds_classification_2_loss: 0.0194 - baseline_loss: 1.0049 - crowds_classification_2_acc: 0.0178 - baseline_acc: 0.8769     \n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0189 - crowds_classification_2_loss: 0.0189 - baseline_loss: 0.9991 - crowds_classification_2_acc: 0.0175 - baseline_acc: 0.8796     \n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0187 - crowds_classification_2_loss: 0.0187 - baseline_loss: 1.0169 - crowds_classification_2_acc: 0.0178 - baseline_acc: 0.8765     \n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0190 - crowds_classification_2_loss: 0.0190 - baseline_loss: 1.0044 - crowds_classification_2_acc: 0.0175 - baseline_acc: 0.8683     \n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0180 - crowds_classification_2_loss: 0.0180 - baseline_loss: 0.9703 - crowds_classification_2_acc: 0.0178 - baseline_acc: 0.8779     \n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0181 - crowds_classification_2_loss: 0.0181 - baseline_loss: 1.0293 - crowds_classification_2_acc: 0.0187 - baseline_acc: 0.8740     \n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 3s - loss: 0.0179 - crowds_classification_2_loss: 0.0179 - baseline_loss: 0.9817 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8747     \n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0175 - crowds_classification_2_loss: 0.0175 - baseline_loss: 0.9512 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8745     \n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0171 - crowds_classification_2_loss: 0.0171 - baseline_loss: 0.9492 - crowds_classification_2_acc: 0.0185 - baseline_acc: 0.8768     \n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0171 - crowds_classification_2_loss: 0.0171 - baseline_loss: 0.9301 - crowds_classification_2_acc: 0.0188 - baseline_acc: 0.8763     \n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s - loss: 0.0170 - crowds_classification_2_loss: 0.0170 - baseline_loss: 0.9694 - crowds_classification_2_acc: 0.0184 - baseline_acc: 0.8736     \n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0171 - crowds_classification_2_loss: 0.0171 - baseline_loss: 0.9539 - crowds_classification_2_acc: 0.0182 - baseline_acc: 0.8711     \n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0167 - crowds_classification_2_loss: 0.0167 - baseline_loss: 0.9359 - crowds_classification_2_acc: 0.0177 - baseline_acc: 0.8708     \n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0165 - crowds_classification_2_loss: 0.0165 - baseline_loss: 0.9446 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8740     \n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0160 - crowds_classification_2_loss: 0.0160 - baseline_loss: 0.9632 - crowds_classification_2_acc: 0.0185 - baseline_acc: 0.8784     \n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0162 - crowds_classification_2_loss: 0.0162 - baseline_loss: 0.9579 - crowds_classification_2_acc: 0.0181 - baseline_acc: 0.8758     \n",
      "Epoch 46/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0164 - crowds_classification_2_loss: 0.0164 - baseline_loss: 0.9238 - crowds_classification_2_acc: 0.0179 - baseline_acc: 0.8727     \n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0159 - crowds_classification_2_loss: 0.0159 - baseline_loss: 0.9713 - crowds_classification_2_acc: 0.0173 - baseline_acc: 0.8735     \n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0154 - crowds_classification_2_loss: 0.0154 - baseline_loss: 0.9395 - crowds_classification_2_acc: 0.0173 - baseline_acc: 0.8777     \n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 2s - loss: 0.0153 - crowds_classification_2_loss: 0.0153 - baseline_loss: 0.9079 - crowds_classification_2_acc: 0.0174 - baseline_acc: 0.8774     \n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0152 - crowds_classification_2_loss: 0.0152 - baseline_loss: 0.9160 - crowds_classification_2_acc: 0.0173 - baseline_acc: 0.876 - 2s - loss: 0.0152 - crowds_classification_2_loss: 0.0152 - baseline_loss: 0.9134 - crowds_classification_2_acc: 0.0173 - baseline_acc: 0.8771     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129601b38>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.fit(data_train_vgg16, [answers_bin_missings, labels_train_mv_bin], epochs=N_EPOCHS, shuffle=True, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_acc': 0.8291245791245792,\n",
       " 'baseline_loss': 1.1054960393945779,\n",
       " 'crowds_classification_2_acc': 0.034722222222222224,\n",
       " 'crowds_classification_2_loss': 0.9964053753249171,\n",
       " 'loss': 0.9964053753249171}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(simple_model,y_test=[answers_test_bin_missings,labels_test_bin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'crowds_classification_1/Reshape_2:0' shape=(?, 8, 59) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channeled_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
